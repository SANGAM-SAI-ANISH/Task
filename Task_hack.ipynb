{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0ICkyFY-Xac",
        "outputId": "0486959f-e6fb-44d2-81cd-4245fdc55088"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training fold 1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 14ms/step - accuracy: 0.7816 - loss: 0.8525 - val_accuracy: 0.9425 - val_loss: 0.1834\n",
            "Epoch 2/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9393 - loss: 0.1974 - val_accuracy: 0.9500 - val_loss: 0.1574\n",
            "Epoch 3/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9515 - loss: 0.1663 - val_accuracy: 0.9431 - val_loss: 0.1740\n",
            "Epoch 4/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.9566 - loss: 0.1397 - val_accuracy: 0.9506 - val_loss: 0.1424\n",
            "Epoch 5/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9555 - loss: 0.1337 - val_accuracy: 0.9600 - val_loss: 0.1248\n",
            "Epoch 6/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9594 - loss: 0.1285 - val_accuracy: 0.9606 - val_loss: 0.1316\n",
            "Epoch 7/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9628 - loss: 0.1298 - val_accuracy: 0.9638 - val_loss: 0.1147\n",
            "Epoch 8/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9655 - loss: 0.1212 - val_accuracy: 0.9575 - val_loss: 0.1252\n",
            "Epoch 9/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9658 - loss: 0.1108 - val_accuracy: 0.9619 - val_loss: 0.1143\n",
            "Epoch 10/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.9625 - loss: 0.1133 - val_accuracy: 0.9600 - val_loss: 0.1168\n",
            "Epoch 11/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9689 - loss: 0.1068 - val_accuracy: 0.9619 - val_loss: 0.1142\n",
            "Epoch 12/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9670 - loss: 0.0983 - val_accuracy: 0.9644 - val_loss: 0.1093\n",
            "Epoch 13/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9637 - loss: 0.1075 - val_accuracy: 0.9650 - val_loss: 0.1037\n",
            "Epoch 14/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9658 - loss: 0.1025 - val_accuracy: 0.9631 - val_loss: 0.0997\n",
            "Epoch 15/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.9657 - loss: 0.1017 - val_accuracy: 0.9631 - val_loss: 0.1052\n",
            "Epoch 16/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.9657 - loss: 0.0954 - val_accuracy: 0.9669 - val_loss: 0.1042\n",
            "Epoch 17/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9739 - loss: 0.0861 - val_accuracy: 0.9669 - val_loss: 0.0981\n",
            "Epoch 18/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9726 - loss: 0.0835 - val_accuracy: 0.9681 - val_loss: 0.1026\n",
            "Epoch 19/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.9741 - loss: 0.0867 - val_accuracy: 0.9669 - val_loss: 0.1098\n",
            "Epoch 20/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.9725 - loss: 0.0829 - val_accuracy: 0.9700 - val_loss: 0.1078\n",
            "Epoch 21/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9713 - loss: 0.0875 - val_accuracy: 0.9700 - val_loss: 0.0997\n",
            "Epoch 22/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9733 - loss: 0.0757 - val_accuracy: 0.9688 - val_loss: 0.1026\n",
            "\n",
            "Training fold 2...\n",
            "Epoch 1/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - accuracy: 0.7768 - loss: 0.8477 - val_accuracy: 0.9400 - val_loss: 0.1705\n",
            "Epoch 2/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.9384 - loss: 0.1910 - val_accuracy: 0.9588 - val_loss: 0.1309\n",
            "Epoch 3/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.9510 - loss: 0.1645 - val_accuracy: 0.9594 - val_loss: 0.1232\n",
            "Epoch 4/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9490 - loss: 0.1559 - val_accuracy: 0.9619 - val_loss: 0.1181\n",
            "Epoch 5/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9533 - loss: 0.1398 - val_accuracy: 0.9594 - val_loss: 0.1171\n",
            "Epoch 6/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9534 - loss: 0.1426 - val_accuracy: 0.9625 - val_loss: 0.1063\n",
            "Epoch 7/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9592 - loss: 0.1294 - val_accuracy: 0.9619 - val_loss: 0.1033\n",
            "Epoch 8/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.9572 - loss: 0.1323 - val_accuracy: 0.9656 - val_loss: 0.1007\n",
            "Epoch 9/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.9572 - loss: 0.1366 - val_accuracy: 0.9675 - val_loss: 0.1026\n",
            "Epoch 10/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9587 - loss: 0.1288 - val_accuracy: 0.9644 - val_loss: 0.0988\n",
            "Epoch 11/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9576 - loss: 0.1252 - val_accuracy: 0.9681 - val_loss: 0.0948\n",
            "Epoch 12/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.9661 - loss: 0.1070 - val_accuracy: 0.9675 - val_loss: 0.0911\n",
            "Epoch 13/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9609 - loss: 0.1202 - val_accuracy: 0.9631 - val_loss: 0.1007\n",
            "Epoch 14/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9566 - loss: 0.1269 - val_accuracy: 0.9619 - val_loss: 0.1090\n",
            "Epoch 15/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9625 - loss: 0.1123 - val_accuracy: 0.9712 - val_loss: 0.0923\n",
            "Epoch 16/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9644 - loss: 0.1087 - val_accuracy: 0.9719 - val_loss: 0.0853\n",
            "Epoch 17/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.9694 - loss: 0.1004 - val_accuracy: 0.9725 - val_loss: 0.0948\n",
            "Epoch 18/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9581 - loss: 0.1172 - val_accuracy: 0.9700 - val_loss: 0.0962\n",
            "Epoch 19/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9681 - loss: 0.1006 - val_accuracy: 0.9700 - val_loss: 0.0879\n",
            "Epoch 20/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9717 - loss: 0.0895 - val_accuracy: 0.9681 - val_loss: 0.0960\n",
            "Epoch 21/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9679 - loss: 0.0933 - val_accuracy: 0.9712 - val_loss: 0.0884\n",
            "\n",
            "Training fold 3...\n",
            "Epoch 1/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - accuracy: 0.7954 - loss: 0.8218 - val_accuracy: 0.9406 - val_loss: 0.1716\n",
            "Epoch 2/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.9459 - loss: 0.1848 - val_accuracy: 0.9481 - val_loss: 0.1537\n",
            "Epoch 3/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.9456 - loss: 0.1765 - val_accuracy: 0.9481 - val_loss: 0.1610\n",
            "Epoch 4/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9548 - loss: 0.1463 - val_accuracy: 0.9581 - val_loss: 0.1314\n",
            "Epoch 5/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9618 - loss: 0.1201 - val_accuracy: 0.9606 - val_loss: 0.1226\n",
            "Epoch 6/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9614 - loss: 0.1275 - val_accuracy: 0.9550 - val_loss: 0.1322\n",
            "Epoch 7/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9565 - loss: 0.1364 - val_accuracy: 0.9644 - val_loss: 0.1160\n",
            "Epoch 8/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.9618 - loss: 0.1175 - val_accuracy: 0.9600 - val_loss: 0.1265\n",
            "Epoch 9/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9647 - loss: 0.1132 - val_accuracy: 0.9600 - val_loss: 0.1241\n",
            "Epoch 10/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9639 - loss: 0.1176 - val_accuracy: 0.9575 - val_loss: 0.1265\n",
            "Epoch 11/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9611 - loss: 0.1158 - val_accuracy: 0.9600 - val_loss: 0.1164\n",
            "Epoch 12/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9684 - loss: 0.0997 - val_accuracy: 0.9669 - val_loss: 0.1111\n",
            "Epoch 13/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9669 - loss: 0.1025 - val_accuracy: 0.9656 - val_loss: 0.1124\n",
            "Epoch 14/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9664 - loss: 0.0941 - val_accuracy: 0.9681 - val_loss: 0.1083\n",
            "Epoch 15/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9663 - loss: 0.0988 - val_accuracy: 0.9631 - val_loss: 0.1152\n",
            "Epoch 16/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9663 - loss: 0.0943 - val_accuracy: 0.9650 - val_loss: 0.1053\n",
            "Epoch 17/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.9706 - loss: 0.0871 - val_accuracy: 0.9669 - val_loss: 0.1112\n",
            "Epoch 18/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9703 - loss: 0.0938 - val_accuracy: 0.9669 - val_loss: 0.1090\n",
            "Epoch 19/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9694 - loss: 0.1048 - val_accuracy: 0.9606 - val_loss: 0.1202\n",
            "Epoch 20/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9765 - loss: 0.0730 - val_accuracy: 0.9663 - val_loss: 0.1063\n",
            "Epoch 21/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9771 - loss: 0.0738 - val_accuracy: 0.9675 - val_loss: 0.1141\n",
            "\n",
            "Training fold 4...\n",
            "Epoch 1/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.7697 - loss: 0.8554 - val_accuracy: 0.9506 - val_loss: 0.1920\n",
            "Epoch 2/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9405 - loss: 0.1856 - val_accuracy: 0.9544 - val_loss: 0.1546\n",
            "Epoch 3/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9491 - loss: 0.1595 - val_accuracy: 0.9581 - val_loss: 0.1443\n",
            "Epoch 4/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.9476 - loss: 0.1613 - val_accuracy: 0.9606 - val_loss: 0.1389\n",
            "Epoch 5/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.9591 - loss: 0.1320 - val_accuracy: 0.9606 - val_loss: 0.1419\n",
            "Epoch 6/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9582 - loss: 0.1295 - val_accuracy: 0.9500 - val_loss: 0.1530\n",
            "Epoch 7/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9547 - loss: 0.1371 - val_accuracy: 0.9638 - val_loss: 0.1273\n",
            "Epoch 8/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.9615 - loss: 0.1188 - val_accuracy: 0.9631 - val_loss: 0.1213\n",
            "Epoch 9/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9583 - loss: 0.1268 - val_accuracy: 0.9638 - val_loss: 0.1166\n",
            "Epoch 10/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9603 - loss: 0.1213 - val_accuracy: 0.9619 - val_loss: 0.1215\n",
            "Epoch 11/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9658 - loss: 0.1124 - val_accuracy: 0.9619 - val_loss: 0.1154\n",
            "Epoch 12/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9627 - loss: 0.1118 - val_accuracy: 0.9631 - val_loss: 0.1136\n",
            "Epoch 13/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.9709 - loss: 0.1010 - val_accuracy: 0.9619 - val_loss: 0.1189\n",
            "Epoch 14/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9619 - loss: 0.1094 - val_accuracy: 0.9650 - val_loss: 0.1122\n",
            "Epoch 15/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9629 - loss: 0.1097 - val_accuracy: 0.9588 - val_loss: 0.1155\n",
            "Epoch 16/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9658 - loss: 0.1065 - val_accuracy: 0.9644 - val_loss: 0.1108\n",
            "Epoch 17/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9637 - loss: 0.0976 - val_accuracy: 0.9675 - val_loss: 0.1027\n",
            "Epoch 18/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.9705 - loss: 0.0951 - val_accuracy: 0.9681 - val_loss: 0.1021\n",
            "Epoch 19/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.9735 - loss: 0.0811 - val_accuracy: 0.9675 - val_loss: 0.1081\n",
            "Epoch 20/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9734 - loss: 0.0859 - val_accuracy: 0.9663 - val_loss: 0.1026\n",
            "Epoch 21/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9741 - loss: 0.0815 - val_accuracy: 0.9719 - val_loss: 0.1033\n",
            "Epoch 22/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.9691 - loss: 0.0775 - val_accuracy: 0.9669 - val_loss: 0.1079\n",
            "Epoch 23/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9732 - loss: 0.0802 - val_accuracy: 0.9694 - val_loss: 0.1024\n",
            "\n",
            "Training fold 5...\n",
            "Epoch 1/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - accuracy: 0.7615 - loss: 0.8580 - val_accuracy: 0.9381 - val_loss: 0.2037\n",
            "Epoch 2/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.9376 - loss: 0.1955 - val_accuracy: 0.9506 - val_loss: 0.1725\n",
            "Epoch 3/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9488 - loss: 0.1586 - val_accuracy: 0.9594 - val_loss: 0.1490\n",
            "Epoch 4/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9475 - loss: 0.1594 - val_accuracy: 0.9581 - val_loss: 0.1479\n",
            "Epoch 5/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.9497 - loss: 0.1442 - val_accuracy: 0.9388 - val_loss: 0.2128\n",
            "Epoch 6/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9559 - loss: 0.1377 - val_accuracy: 0.9600 - val_loss: 0.1403\n",
            "Epoch 7/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9587 - loss: 0.1281 - val_accuracy: 0.9606 - val_loss: 0.1352\n",
            "Epoch 8/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9628 - loss: 0.1212 - val_accuracy: 0.9613 - val_loss: 0.1327\n",
            "Epoch 9/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9612 - loss: 0.1198 - val_accuracy: 0.9613 - val_loss: 0.1393\n",
            "Epoch 10/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.9616 - loss: 0.1147 - val_accuracy: 0.9600 - val_loss: 0.1343\n",
            "Epoch 11/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9653 - loss: 0.1048 - val_accuracy: 0.9469 - val_loss: 0.1749\n",
            "Epoch 12/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9609 - loss: 0.1100 - val_accuracy: 0.9625 - val_loss: 0.1190\n",
            "Epoch 13/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.9671 - loss: 0.1028 - val_accuracy: 0.9606 - val_loss: 0.1271\n",
            "Epoch 14/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.9684 - loss: 0.1018 - val_accuracy: 0.9613 - val_loss: 0.1218\n",
            "Epoch 15/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9684 - loss: 0.1027 - val_accuracy: 0.9575 - val_loss: 0.1297\n",
            "Epoch 16/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9649 - loss: 0.1047 - val_accuracy: 0.9613 - val_loss: 0.1322\n",
            "Epoch 17/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.9711 - loss: 0.0891 - val_accuracy: 0.9650 - val_loss: 0.1176\n",
            "Epoch 18/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9691 - loss: 0.0969 - val_accuracy: 0.9644 - val_loss: 0.1181\n",
            "Epoch 19/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9723 - loss: 0.0854 - val_accuracy: 0.9663 - val_loss: 0.1156\n",
            "Epoch 20/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9728 - loss: 0.0869 - val_accuracy: 0.9644 - val_loss: 0.1094\n",
            "Epoch 21/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.9744 - loss: 0.0827 - val_accuracy: 0.9700 - val_loss: 0.1107\n",
            "Epoch 22/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.9743 - loss: 0.0801 - val_accuracy: 0.9656 - val_loss: 0.1143\n",
            "Epoch 23/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9718 - loss: 0.0856 - val_accuracy: 0.9700 - val_loss: 0.1081\n",
            "Epoch 24/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9720 - loss: 0.0809 - val_accuracy: 0.9606 - val_loss: 0.1212\n",
            "Epoch 25/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.9747 - loss: 0.0716 - val_accuracy: 0.9638 - val_loss: 0.1142\n",
            "Epoch 26/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9728 - loss: 0.0774 - val_accuracy: 0.9644 - val_loss: 0.1196\n",
            "Epoch 27/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9712 - loss: 0.0777 - val_accuracy: 0.9675 - val_loss: 0.1168\n",
            "Epoch 28/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9754 - loss: 0.0817 - val_accuracy: 0.9606 - val_loss: 0.1204\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.metrics import classification_report\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Conv1D, MaxPooling1D, Flatten, Bidirectional, GRU\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "def load_and_preprocess():\n",
        "    df = pd.read_csv(\"hacktrain.csv\")\n",
        "    df.fillna(df.mean(numeric_only=True), inplace=True)\n",
        "    df.drop(columns=['ID'], inplace=True)\n",
        "\n",
        "    label_encoder = LabelEncoder()\n",
        "    df['class'] = label_encoder.fit_transform(df['class'])\n",
        "\n",
        "    X = df.drop(columns=['class']).values\n",
        "    y = df['class'].values\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X = scaler.fit_transform(X)\n",
        "    X = X.reshape(X.shape[0], X.shape[1], 1)\n",
        "    y = to_categorical(y)\n",
        "    return X, y, label_encoder, scaler\n",
        "\n",
        "def create_bigru_model(input_shape, num_classes):\n",
        "    model = Sequential([\n",
        "        Bidirectional(GRU(64, return_sequences=True), input_shape=input_shape),\n",
        "        Dropout(0.3),\n",
        "        Bidirectional(GRU(32)),\n",
        "        Dropout(0.3),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "                 loss='categorical_crossentropy',\n",
        "                 metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def create_cnn_model(input_shape, num_classes):\n",
        "    model = Sequential([\n",
        "        Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=input_shape),\n",
        "        MaxPooling1D(pool_size=2),\n",
        "        Conv1D(filters=128, kernel_size=3, activation='relu'),\n",
        "        MaxPooling1D(pool_size=2),\n",
        "        Flatten(),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "                 loss='categorical_crossentropy',\n",
        "                 metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def kfold_cross_validation(X, y, model_type='bigru', n_splits=5, epochs=50, batch_size=32):\n",
        "    kfold = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "    fold_no = 1\n",
        "    histories = []\n",
        "\n",
        "    y_labels = np.argmax(y, axis=1)\n",
        "\n",
        "    for train_idx, val_idx in kfold.split(X, y_labels):\n",
        "        print(f'\\nTraining fold {fold_no}...')\n",
        "\n",
        "        if model_type == 'bigru':\n",
        "            model = create_bigru_model((X.shape[1], X.shape[2]), y.shape[1])\n",
        "        else:\n",
        "            model = create_cnn_model((X.shape[1], X.shape[2]), y.shape[1])\n",
        "\n",
        "        es = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "        history = model.fit(\n",
        "            X[train_idx], y[train_idx],\n",
        "            validation_data=(X[val_idx], y[val_idx]),\n",
        "            epochs=epochs,\n",
        "            batch_size=batch_size,\n",
        "            callbacks=[es],\n",
        "            verbose=1\n",
        "        )\n",
        "\n",
        "        histories.append(history)\n",
        "        fold_no += 1\n",
        "\n",
        "    return model, histories\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    X, y, label_encoder, scaler = load_and_preprocess()\n",
        "\n",
        "    trained_model, histories = kfold_cross_validation(X, y, model_type='bigru')\n",
        "\n",
        "    test_data = pd.read_csv(\"hacktest.csv\")\n",
        "    ID = test_data['ID']\n",
        "    test_data.drop(['ID'], axis=1, inplace=True)\n",
        "\n",
        "    X_test = scaler.transform(test_data.values)\n",
        "    X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
        "\n",
        "    y_pred_probs = trained_model.predict(X_test)\n",
        "    y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "    y_decoded = label_encoder.inverse_transform(y_pred)\n",
        "\n",
        "    # Save results\n",
        "    result = pd.DataFrame({\n",
        "        'ID': ID,\n",
        "        'class': y_decoded\n",
        "    })\n",
        "    result.to_csv(\"bigru.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Bidirectional, GRU, Dropout, BatchNormalization\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from sklearn.metrics import classification_report\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "df = pd.read_csv(\"hacktrain.csv\")\n",
        "df.fillna(df.mean(numeric_only=True), inplace=True)\n",
        "df.drop(columns=['ID'], inplace=True)\n",
        "label_encoder = LabelEncoder()\n",
        "df['class'] = label_encoder.fit_transform(df['class'])\n",
        "X = df.drop(columns=['class']).values\n",
        "y = df['class'].values\n",
        "y_encoded = to_categorical(y)\n",
        "\n",
        "n_splits = 5\n",
        "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "fold_scores = []\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
        "    X_train, X_val = X[train_idx], X[val_idx]\n",
        "    y_train, y_val = y_encoded[train_idx], y_encoded[val_idx]\n",
        "\n",
        "    X_train_reshaped = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "    X_val_reshaped = X_val.reshape(X_val.shape[0], X_val.shape[1], 1)\n",
        "\n",
        "    model = Sequential([\n",
        "        Bidirectional(GRU(128, return_sequences=True), input_shape=(X_train.shape[1], 1)),\n",
        "        BatchNormalization(),\n",
        "        Bidirectional(GRU(64)),\n",
        "        BatchNormalization(),\n",
        "        Dense(256, activation='relu'),\n",
        "        Dropout(0.4),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dropout(0.3),\n",
        "        Dense(len(label_encoder.classes_), activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "    lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6)\n",
        "\n",
        "    model.fit(X_train_reshaped, y_train, epochs=50, batch_size=64,\n",
        "              validation_data=(X_val_reshaped, y_val),\n",
        "              callbacks=[early_stopping, lr_reducer], verbose=0)\n",
        "\n",
        "    y_pred = model.predict(X_val_reshaped)\n",
        "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "    y_val_classes = np.argmax(y_val, axis=1)\n",
        "    fold_scores.append(classification_report(y_val_classes, y_pred_classes,\n",
        "                                            labels=list(range(len(label_encoder.classes_))),\n",
        "                                            target_names=label_encoder.classes_, output_dict=True))\n",
        "\n",
        "test_data = pd.read_csv(\"hacktest.csv\")\n",
        "ID = test_data['ID']\n",
        "test_data.drop(['ID'], axis=1, inplace=True)\n",
        "X_test = test_data.values\n",
        "X_test_reshaped = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
        "y_test_pred = model.predict(X_test_reshaped)\n",
        "y_test_classes = np.argmax(y_test_pred, axis=1)\n",
        "y_decoded = label_encoder.inverse_transform(y_test_classes)\n",
        "\n",
        "result = pd.DataFrame({'ID': ID, 'class': y_decoded})\n",
        "result.to_csv(\"submission_bigru.csv\", index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "irjafmeB-6g8",
        "outputId": "ac8d4b91-c29d-41ea-f769-c17a4dadcbdd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m31/89\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FC5YvfCvBJG-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.metrics import classification_report\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Conv1D, MaxPooling1D, Flatten, Bidirectional, GRU\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "def load_and_preprocess():\n",
        "    df = pd.read_csv(\"hacktrain.csv\")\n",
        "    df.fillna(df.mean(numeric_only=True), inplace=True)\n",
        "    df.drop(columns=['ID'], inplace=True)\n",
        "\n",
        "    label_encoder = LabelEncoder()\n",
        "    df['class'] = label_encoder.fit_transform(df['class'])\n",
        "\n",
        "    X = df.drop(columns=['class']).values\n",
        "    y = df['class'].values\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X = scaler.fit_transform(X)\n",
        "    X = X.reshape(X.shape[0], X.shape[1], 1)\n",
        "    y = to_categorical(y)\n",
        "    return X, y, label_encoder, scaler\n",
        "\n",
        "def create_bigru_model(input_shape, num_classes):\n",
        "    model = Sequential([\n",
        "        Bidirectional(GRU(64, return_sequences=True), input_shape=input_shape),\n",
        "        Dropout(0.3),\n",
        "        Bidirectional(GRU(32)),\n",
        "        Dropout(0.3),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "                 loss='categorical_crossentropy',\n",
        "                 metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def create_cnn_model(input_shape, num_classes):\n",
        "    model = Sequential([\n",
        "        Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=input_shape),\n",
        "        MaxPooling1D(pool_size=2),\n",
        "        Conv1D(filters=128, kernel_size=3, activation='relu'),\n",
        "        MaxPooling1D(pool_size=2),\n",
        "        Flatten(),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "                 loss='categorical_crossentropy',\n",
        "                 metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def kfold_cross_validation(X, y, model_type='bigru', n_splits=5, epochs=50, batch_size=32):\n",
        "    kfold = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "    fold_no = 1\n",
        "    histories = []\n",
        "\n",
        "    y_labels = np.argmax(y, axis=1)\n",
        "\n",
        "    for train_idx, val_idx in kfold.split(X, y_labels):\n",
        "        print(f'\\nTraining fold {fold_no}...')\n",
        "\n",
        "        if model_type == 'bigru':\n",
        "            model = create_bigru_model((X.shape[1], X.shape[2]), y.shape[1])\n",
        "        else:\n",
        "            model = create_cnn_model((X.shape[1], X.shape[2]), y.shape[1])\n",
        "\n",
        "        es = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "        history = model.fit(\n",
        "            X[train_idx], y[train_idx],\n",
        "            validation_data=(X[val_idx], y[val_idx]),\n",
        "            epochs=epochs,\n",
        "            batch_size=batch_size,\n",
        "            callbacks=[es],\n",
        "            verbose=1\n",
        "        )\n",
        "\n",
        "        histories.append(history)\n",
        "        fold_no += 1\n",
        "\n",
        "    return model, histories\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    X, y, label_encoder, scaler = load_and_preprocess()\n",
        "\n",
        "    trained_model, histories = kfold_cross_validation(X, y, model_type='cnn')\n",
        "\n",
        "    test_data = pd.read_csv(\"hacktest.csv\")\n",
        "    ID = test_data['ID']\n",
        "    test_data.drop(['ID'], axis=1, inplace=True)\n",
        "\n",
        "    X_test = scaler.transform(test_data.values)\n",
        "    X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
        "\n",
        "    y_pred_probs = trained_model.predict(X_test)\n",
        "    y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "    y_decoded = label_encoder.inverse_transform(y_pred)\n",
        "\n",
        "    result = pd.DataFrame({\n",
        "        'ID': ID,\n",
        "        'class': y_decoded\n",
        "    })\n",
        "    result.to_csv(\"cnn.csv\", index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4VUbv59Bu6g",
        "outputId": "f30efc29-8738-4de2-ba81-a92bd6041fb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training fold 1...\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7983 - loss: 0.6754 - val_accuracy: 0.9231 - val_loss: 0.2555\n",
            "Epoch 2/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9265 - loss: 0.2468 - val_accuracy: 0.9500 - val_loss: 0.1655\n",
            "Epoch 3/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9426 - loss: 0.1903 - val_accuracy: 0.9575 - val_loss: 0.1517\n",
            "Epoch 4/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9520 - loss: 0.1602 - val_accuracy: 0.9606 - val_loss: 0.1338\n",
            "Epoch 5/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9568 - loss: 0.1492 - val_accuracy: 0.9681 - val_loss: 0.1272\n",
            "Epoch 6/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9615 - loss: 0.1302 - val_accuracy: 0.9638 - val_loss: 0.1204\n",
            "Epoch 7/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9610 - loss: 0.1157 - val_accuracy: 0.9669 - val_loss: 0.1094\n",
            "Epoch 8/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9650 - loss: 0.1142 - val_accuracy: 0.9675 - val_loss: 0.1086\n",
            "Epoch 9/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9720 - loss: 0.0955 - val_accuracy: 0.9663 - val_loss: 0.1090\n",
            "Epoch 10/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9744 - loss: 0.0860 - val_accuracy: 0.9625 - val_loss: 0.1150\n",
            "Epoch 11/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9775 - loss: 0.0803 - val_accuracy: 0.9644 - val_loss: 0.1073\n",
            "Epoch 12/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9742 - loss: 0.0837 - val_accuracy: 0.9663 - val_loss: 0.1056\n",
            "Epoch 13/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9788 - loss: 0.0733 - val_accuracy: 0.9681 - val_loss: 0.1042\n",
            "Epoch 14/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9797 - loss: 0.0638 - val_accuracy: 0.9581 - val_loss: 0.1576\n",
            "Epoch 15/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9761 - loss: 0.0809 - val_accuracy: 0.9700 - val_loss: 0.1047\n",
            "Epoch 16/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9819 - loss: 0.0534 - val_accuracy: 0.9688 - val_loss: 0.1074\n",
            "Epoch 17/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9804 - loss: 0.0614 - val_accuracy: 0.9681 - val_loss: 0.1238\n",
            "Epoch 18/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9827 - loss: 0.0509 - val_accuracy: 0.9644 - val_loss: 0.1159\n",
            "\n",
            "Training fold 2...\n",
            "Epoch 1/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8022 - loss: 0.6670 - val_accuracy: 0.9119 - val_loss: 0.2491\n",
            "Epoch 2/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9277 - loss: 0.2393 - val_accuracy: 0.9550 - val_loss: 0.1600\n",
            "Epoch 3/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9414 - loss: 0.1953 - val_accuracy: 0.9638 - val_loss: 0.1341\n",
            "Epoch 4/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9514 - loss: 0.1674 - val_accuracy: 0.9638 - val_loss: 0.1202\n",
            "Epoch 5/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9545 - loss: 0.1503 - val_accuracy: 0.9656 - val_loss: 0.1162\n",
            "Epoch 6/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9581 - loss: 0.1346 - val_accuracy: 0.9656 - val_loss: 0.1152\n",
            "Epoch 7/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9664 - loss: 0.1138 - val_accuracy: 0.9613 - val_loss: 0.1189\n",
            "Epoch 8/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9626 - loss: 0.1188 - val_accuracy: 0.9663 - val_loss: 0.1102\n",
            "Epoch 9/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9669 - loss: 0.1035 - val_accuracy: 0.9706 - val_loss: 0.1097\n",
            "Epoch 10/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9699 - loss: 0.1002 - val_accuracy: 0.9675 - val_loss: 0.1049\n",
            "Epoch 11/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9736 - loss: 0.0959 - val_accuracy: 0.9663 - val_loss: 0.1060\n",
            "Epoch 12/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9749 - loss: 0.0804 - val_accuracy: 0.9675 - val_loss: 0.1047\n",
            "Epoch 13/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9770 - loss: 0.0703 - val_accuracy: 0.9725 - val_loss: 0.1017\n",
            "Epoch 14/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9747 - loss: 0.0819 - val_accuracy: 0.9712 - val_loss: 0.0999\n",
            "Epoch 15/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9821 - loss: 0.0565 - val_accuracy: 0.9688 - val_loss: 0.1019\n",
            "Epoch 16/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9782 - loss: 0.0648 - val_accuracy: 0.9712 - val_loss: 0.0966\n",
            "Epoch 17/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9815 - loss: 0.0601 - val_accuracy: 0.9725 - val_loss: 0.0980\n",
            "Epoch 18/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9810 - loss: 0.0570 - val_accuracy: 0.9725 - val_loss: 0.0986\n",
            "Epoch 19/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9812 - loss: 0.0592 - val_accuracy: 0.9744 - val_loss: 0.1043\n",
            "Epoch 20/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9845 - loss: 0.0429 - val_accuracy: 0.9706 - val_loss: 0.1056\n",
            "Epoch 21/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9876 - loss: 0.0395 - val_accuracy: 0.9706 - val_loss: 0.1094\n",
            "\n",
            "Training fold 3...\n",
            "Epoch 1/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7847 - loss: 0.7004 - val_accuracy: 0.9069 - val_loss: 0.2772\n",
            "Epoch 2/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9118 - loss: 0.2714 - val_accuracy: 0.9381 - val_loss: 0.1839\n",
            "Epoch 3/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9362 - loss: 0.2039 - val_accuracy: 0.9525 - val_loss: 0.1604\n",
            "Epoch 4/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9551 - loss: 0.1574 - val_accuracy: 0.9563 - val_loss: 0.1425\n",
            "Epoch 5/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9556 - loss: 0.1491 - val_accuracy: 0.9575 - val_loss: 0.1331\n",
            "Epoch 6/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9602 - loss: 0.1274 - val_accuracy: 0.9556 - val_loss: 0.1408\n",
            "Epoch 7/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9624 - loss: 0.1067 - val_accuracy: 0.9581 - val_loss: 0.1327\n",
            "Epoch 8/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9640 - loss: 0.1124 - val_accuracy: 0.9594 - val_loss: 0.1196\n",
            "Epoch 9/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9698 - loss: 0.0934 - val_accuracy: 0.9619 - val_loss: 0.1121\n",
            "Epoch 10/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9712 - loss: 0.0898 - val_accuracy: 0.9600 - val_loss: 0.1191\n",
            "Epoch 11/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9711 - loss: 0.0844 - val_accuracy: 0.9600 - val_loss: 0.1216\n",
            "Epoch 12/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9748 - loss: 0.0862 - val_accuracy: 0.9644 - val_loss: 0.1281\n",
            "Epoch 13/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9794 - loss: 0.0737 - val_accuracy: 0.9619 - val_loss: 0.1251\n",
            "Epoch 14/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9751 - loss: 0.0764 - val_accuracy: 0.9606 - val_loss: 0.1205\n",
            "\n",
            "Training fold 4...\n",
            "Epoch 1/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7684 - loss: 0.7563 - val_accuracy: 0.8994 - val_loss: 0.3298\n",
            "Epoch 2/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9151 - loss: 0.2722 - val_accuracy: 0.9413 - val_loss: 0.1960\n",
            "Epoch 3/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9422 - loss: 0.2074 - val_accuracy: 0.9525 - val_loss: 0.1665\n",
            "Epoch 4/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9544 - loss: 0.1594 - val_accuracy: 0.9581 - val_loss: 0.1561\n",
            "Epoch 5/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9572 - loss: 0.1503 - val_accuracy: 0.9544 - val_loss: 0.1580\n",
            "Epoch 6/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9634 - loss: 0.1221 - val_accuracy: 0.9556 - val_loss: 0.1466\n",
            "Epoch 7/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9617 - loss: 0.1224 - val_accuracy: 0.9556 - val_loss: 0.1748\n",
            "Epoch 8/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9686 - loss: 0.0983 - val_accuracy: 0.9550 - val_loss: 0.1479\n",
            "Epoch 9/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9714 - loss: 0.0965 - val_accuracy: 0.9513 - val_loss: 0.1510\n",
            "Epoch 10/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9689 - loss: 0.0981 - val_accuracy: 0.9513 - val_loss: 0.1390\n",
            "Epoch 11/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9757 - loss: 0.0801 - val_accuracy: 0.9613 - val_loss: 0.1376\n",
            "Epoch 12/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9740 - loss: 0.0830 - val_accuracy: 0.9606 - val_loss: 0.1344\n",
            "Epoch 13/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9756 - loss: 0.0756 - val_accuracy: 0.9538 - val_loss: 0.1436\n",
            "Epoch 14/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9777 - loss: 0.0706 - val_accuracy: 0.9606 - val_loss: 0.1566\n",
            "Epoch 15/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9789 - loss: 0.0687 - val_accuracy: 0.9525 - val_loss: 0.1616\n",
            "Epoch 16/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9779 - loss: 0.0714 - val_accuracy: 0.9594 - val_loss: 0.1479\n",
            "Epoch 17/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9837 - loss: 0.0501 - val_accuracy: 0.9613 - val_loss: 0.1686\n",
            "\n",
            "Training fold 5...\n",
            "Epoch 1/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7884 - loss: 0.7037 - val_accuracy: 0.9025 - val_loss: 0.2980\n",
            "Epoch 2/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9163 - loss: 0.2774 - val_accuracy: 0.9456 - val_loss: 0.1899\n",
            "Epoch 3/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9466 - loss: 0.1778 - val_accuracy: 0.9544 - val_loss: 0.1669\n",
            "Epoch 4/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9548 - loss: 0.1526 - val_accuracy: 0.9506 - val_loss: 0.1744\n",
            "Epoch 5/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9591 - loss: 0.1357 - val_accuracy: 0.9500 - val_loss: 0.2067\n",
            "Epoch 6/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9598 - loss: 0.1336 - val_accuracy: 0.9544 - val_loss: 0.1537\n",
            "Epoch 7/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9595 - loss: 0.1277 - val_accuracy: 0.9569 - val_loss: 0.1476\n",
            "Epoch 8/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9660 - loss: 0.1082 - val_accuracy: 0.9600 - val_loss: 0.1391\n",
            "Epoch 9/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9655 - loss: 0.1055 - val_accuracy: 0.9575 - val_loss: 0.1356\n",
            "Epoch 10/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9682 - loss: 0.0984 - val_accuracy: 0.9650 - val_loss: 0.1257\n",
            "Epoch 11/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9736 - loss: 0.0949 - val_accuracy: 0.9663 - val_loss: 0.1243\n",
            "Epoch 12/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9741 - loss: 0.0793 - val_accuracy: 0.9613 - val_loss: 0.1316\n",
            "Epoch 13/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9759 - loss: 0.0807 - val_accuracy: 0.9656 - val_loss: 0.1218\n",
            "Epoch 14/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9747 - loss: 0.0762 - val_accuracy: 0.9638 - val_loss: 0.1385\n",
            "Epoch 15/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9779 - loss: 0.0733 - val_accuracy: 0.9613 - val_loss: 0.1599\n",
            "Epoch 16/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9792 - loss: 0.0670 - val_accuracy: 0.9644 - val_loss: 0.1358\n",
            "Epoch 17/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9809 - loss: 0.0699 - val_accuracy: 0.9644 - val_loss: 0.1261\n",
            "Epoch 18/50\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9808 - loss: 0.0642 - val_accuracy: 0.9619 - val_loss: 0.1576\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.impute import KNNImputer\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Bidirectional, GRU\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "def load_and_preprocess():\n",
        "    df = pd.read_csv(\"hacktrain.csv\")\n",
        "    df.drop(columns=['ID'], inplace=True)\n",
        "\n",
        "    imputer = KNNImputer(n_neighbors=5)\n",
        "    numeric_cols = df.select_dtypes(include=np.number).columns\n",
        "    df[numeric_cols] = imputer.fit_transform(df[numeric_cols])\n",
        "\n",
        "    label_encoder = LabelEncoder()\n",
        "    df['class'] = label_encoder.fit_transform(df['class'])\n",
        "\n",
        "    X = df.drop(columns=['class']).values\n",
        "    y = df['class'].values\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X = scaler.fit_transform(X)\n",
        "    X = X.reshape(X.shape[0], X.shape[1], 1)\n",
        "    y = to_categorical(y)\n",
        "    return X, y, label_encoder, scaler, imputer\n",
        "\n",
        "def create_bigru_model(input_shape, num_classes):\n",
        "    model = Sequential([\n",
        "        Bidirectional(GRU(128, return_sequences=True), input_shape=input_shape),\n",
        "        Dropout(0.4),\n",
        "        Bidirectional(GRU(64)),\n",
        "        Dropout(0.4),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer=Adam(learning_rate=0.0005),\n",
        "                 loss='categorical_crossentropy',\n",
        "                 metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def kfold_cross_validation(X, y, n_splits=5, epochs=100, batch_size=32):\n",
        "    kfold = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "    fold_no = 1\n",
        "    histories = []\n",
        "    y_labels = np.argmax(y, axis=1)\n",
        "\n",
        "    for train_idx, val_idx in kfold.split(X, y_labels):\n",
        "        model = create_bigru_model((X.shape[1], X.shape[2]), y.shape[1])\n",
        "        es = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "        history = model.fit(\n",
        "            X[train_idx], y[train_idx],\n",
        "            validation_data=(X[val_idx], y[val_idx]),\n",
        "            epochs=epochs,\n",
        "            batch_size=batch_size,\n",
        "            callbacks=[es],\n",
        "            verbose=1\n",
        "        )\n",
        "        histories.append(history)\n",
        "        fold_no += 1\n",
        "\n",
        "    return model, histories\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    X, y, label_encoder, scaler, imputer = load_and_preprocess()\n",
        "    trained_model, _ = kfold_cross_validation(X, y)\n",
        "\n",
        "    test_data = pd.read_csv(\"hacktest.csv\")\n",
        "    ID = test_data['ID']\n",
        "    test_data.drop(['ID'], axis=1, inplace=True)\n",
        "\n",
        "    numeric_cols = test_data.select_dtypes(include=np.number).columns\n",
        "    test_data[numeric_cols] = imputer.transform(test_data[numeric_cols])\n",
        "\n",
        "    X_test = scaler.transform(test_data.values)\n",
        "    X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
        "\n",
        "    y_pred = np.argmax(trained_model.predict(X_test), axis=1)\n",
        "    y_decoded = label_encoder.inverse_transform(y_pred)\n",
        "\n",
        "    pd.DataFrame({'ID': ID, 'class': y_decoded}).to_csv(\"bigru_1.csv\", index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "roMMbi_eBw_7",
        "outputId": "a2e0343c-ccf3-40e3-bb23-c141d6f2684a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - accuracy: 0.7722 - loss: 0.9069 - val_accuracy: 0.9431 - val_loss: 0.1875\n",
            "Epoch 2/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.9386 - loss: 0.1973 - val_accuracy: 0.9500 - val_loss: 0.1453\n",
            "Epoch 3/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9501 - loss: 0.1549 - val_accuracy: 0.9538 - val_loss: 0.1337\n",
            "Epoch 4/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9568 - loss: 0.1432 - val_accuracy: 0.9500 - val_loss: 0.1462\n",
            "Epoch 5/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9542 - loss: 0.1402 - val_accuracy: 0.9544 - val_loss: 0.1262\n",
            "Epoch 6/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9600 - loss: 0.1309 - val_accuracy: 0.9600 - val_loss: 0.1206\n",
            "Epoch 7/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.9598 - loss: 0.1253 - val_accuracy: 0.9600 - val_loss: 0.1118\n",
            "Epoch 8/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.9578 - loss: 0.1310 - val_accuracy: 0.9600 - val_loss: 0.1087\n",
            "Epoch 9/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9646 - loss: 0.1016 - val_accuracy: 0.9644 - val_loss: 0.1069\n",
            "Epoch 10/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9650 - loss: 0.1104 - val_accuracy: 0.9625 - val_loss: 0.1066\n",
            "Epoch 11/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.9682 - loss: 0.1046 - val_accuracy: 0.9650 - val_loss: 0.1007\n",
            "Epoch 12/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9601 - loss: 0.1164 - val_accuracy: 0.9638 - val_loss: 0.0997\n",
            "Epoch 13/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9643 - loss: 0.1114 - val_accuracy: 0.9663 - val_loss: 0.0985\n",
            "Epoch 14/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9643 - loss: 0.1088 - val_accuracy: 0.9675 - val_loss: 0.1015\n",
            "Epoch 15/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9646 - loss: 0.0965 - val_accuracy: 0.9669 - val_loss: 0.0943\n",
            "Epoch 16/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.9693 - loss: 0.0885 - val_accuracy: 0.9712 - val_loss: 0.0928\n",
            "Epoch 17/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9659 - loss: 0.1022 - val_accuracy: 0.9731 - val_loss: 0.0905\n",
            "Epoch 18/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9701 - loss: 0.0972 - val_accuracy: 0.9700 - val_loss: 0.0896\n",
            "Epoch 19/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.9661 - loss: 0.0904 - val_accuracy: 0.9712 - val_loss: 0.0875\n",
            "Epoch 20/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9733 - loss: 0.0769 - val_accuracy: 0.9737 - val_loss: 0.0891\n",
            "Epoch 21/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9742 - loss: 0.0897 - val_accuracy: 0.9750 - val_loss: 0.0871\n",
            "Epoch 22/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9727 - loss: 0.0788 - val_accuracy: 0.9700 - val_loss: 0.0873\n",
            "Epoch 23/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9758 - loss: 0.0672 - val_accuracy: 0.9712 - val_loss: 0.0909\n",
            "Epoch 24/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.9745 - loss: 0.0684 - val_accuracy: 0.9731 - val_loss: 0.0845\n",
            "Epoch 25/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.9714 - loss: 0.0855 - val_accuracy: 0.9725 - val_loss: 0.0826\n",
            "Epoch 26/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9753 - loss: 0.0679 - val_accuracy: 0.9669 - val_loss: 0.0923\n",
            "Epoch 27/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9798 - loss: 0.0623 - val_accuracy: 0.9681 - val_loss: 0.0910\n",
            "Epoch 28/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.9741 - loss: 0.0648 - val_accuracy: 0.9706 - val_loss: 0.0898\n",
            "Epoch 29/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.9791 - loss: 0.0665 - val_accuracy: 0.9756 - val_loss: 0.0852\n",
            "Epoch 30/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9800 - loss: 0.0567 - val_accuracy: 0.9694 - val_loss: 0.0927\n",
            "Epoch 31/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9815 - loss: 0.0548 - val_accuracy: 0.9663 - val_loss: 0.0977\n",
            "Epoch 32/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.9802 - loss: 0.0527 - val_accuracy: 0.9725 - val_loss: 0.0862\n",
            "Epoch 33/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9804 - loss: 0.0585 - val_accuracy: 0.9681 - val_loss: 0.0989\n",
            "Epoch 34/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9830 - loss: 0.0602 - val_accuracy: 0.9731 - val_loss: 0.0960\n",
            "Epoch 35/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9828 - loss: 0.0499 - val_accuracy: 0.9744 - val_loss: 0.0838\n",
            "Epoch 1/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 0.7837 - loss: 0.8690 - val_accuracy: 0.9513 - val_loss: 0.1638\n",
            "Epoch 2/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9395 - loss: 0.1932 - val_accuracy: 0.9594 - val_loss: 0.1266\n",
            "Epoch 3/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9553 - loss: 0.1505 - val_accuracy: 0.9575 - val_loss: 0.1279\n",
            "Epoch 4/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9464 - loss: 0.1598 - val_accuracy: 0.9625 - val_loss: 0.1126\n",
            "Epoch 5/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.9519 - loss: 0.1482 - val_accuracy: 0.9625 - val_loss: 0.1152\n",
            "Epoch 6/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9558 - loss: 0.1377 - val_accuracy: 0.9694 - val_loss: 0.1044\n",
            "Epoch 7/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9644 - loss: 0.1236 - val_accuracy: 0.9681 - val_loss: 0.1009\n",
            "Epoch 8/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9556 - loss: 0.1299 - val_accuracy: 0.9675 - val_loss: 0.0963\n",
            "Epoch 9/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9587 - loss: 0.1280 - val_accuracy: 0.9712 - val_loss: 0.0937\n",
            "Epoch 10/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9650 - loss: 0.1178 - val_accuracy: 0.9675 - val_loss: 0.0954\n",
            "Epoch 11/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9649 - loss: 0.1084 - val_accuracy: 0.9706 - val_loss: 0.0881\n",
            "Epoch 12/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9652 - loss: 0.1088 - val_accuracy: 0.9700 - val_loss: 0.0860\n",
            "Epoch 13/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9637 - loss: 0.1218 - val_accuracy: 0.9725 - val_loss: 0.0861\n",
            "Epoch 14/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.9705 - loss: 0.0920 - val_accuracy: 0.9694 - val_loss: 0.0907\n",
            "Epoch 15/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9691 - loss: 0.0952 - val_accuracy: 0.9700 - val_loss: 0.0867\n",
            "Epoch 16/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9692 - loss: 0.1000 - val_accuracy: 0.9725 - val_loss: 0.0878\n",
            "Epoch 17/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9684 - loss: 0.0970 - val_accuracy: 0.9725 - val_loss: 0.0847\n",
            "Epoch 18/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9634 - loss: 0.1116 - val_accuracy: 0.9712 - val_loss: 0.0821\n",
            "Epoch 19/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.9699 - loss: 0.0952 - val_accuracy: 0.9712 - val_loss: 0.0938\n",
            "Epoch 20/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9756 - loss: 0.0774 - val_accuracy: 0.9737 - val_loss: 0.0872\n",
            "Epoch 21/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9760 - loss: 0.0744 - val_accuracy: 0.9688 - val_loss: 0.0937\n",
            "Epoch 22/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9724 - loss: 0.0845 - val_accuracy: 0.9750 - val_loss: 0.0761\n",
            "Epoch 23/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.9719 - loss: 0.0827 - val_accuracy: 0.9737 - val_loss: 0.0778\n",
            "Epoch 24/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.9744 - loss: 0.0817 - val_accuracy: 0.9731 - val_loss: 0.0770\n",
            "Epoch 25/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9755 - loss: 0.0698 - val_accuracy: 0.9769 - val_loss: 0.0793\n",
            "Epoch 26/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9768 - loss: 0.0654 - val_accuracy: 0.9725 - val_loss: 0.0759\n",
            "Epoch 27/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.9768 - loss: 0.0706 - val_accuracy: 0.9744 - val_loss: 0.0813\n",
            "Epoch 28/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.9766 - loss: 0.0689 - val_accuracy: 0.9756 - val_loss: 0.0739\n",
            "Epoch 29/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9796 - loss: 0.0627 - val_accuracy: 0.9775 - val_loss: 0.0756\n",
            "Epoch 30/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9780 - loss: 0.0612 - val_accuracy: 0.9781 - val_loss: 0.0717\n",
            "Epoch 31/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.9790 - loss: 0.0642 - val_accuracy: 0.9819 - val_loss: 0.0712\n",
            "Epoch 32/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.9800 - loss: 0.0602 - val_accuracy: 0.9787 - val_loss: 0.0733\n",
            "Epoch 33/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9807 - loss: 0.0555 - val_accuracy: 0.9769 - val_loss: 0.0714\n",
            "Epoch 34/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9844 - loss: 0.0570 - val_accuracy: 0.9775 - val_loss: 0.0760\n",
            "Epoch 35/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.9809 - loss: 0.0541 - val_accuracy: 0.9806 - val_loss: 0.0675\n",
            "Epoch 36/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9835 - loss: 0.0527 - val_accuracy: 0.9781 - val_loss: 0.0803\n",
            "Epoch 37/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9847 - loss: 0.0442 - val_accuracy: 0.9769 - val_loss: 0.0827\n",
            "Epoch 38/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9832 - loss: 0.0457 - val_accuracy: 0.9762 - val_loss: 0.0777\n",
            "Epoch 39/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9848 - loss: 0.0426 - val_accuracy: 0.9800 - val_loss: 0.0716\n",
            "Epoch 40/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.9822 - loss: 0.0497 - val_accuracy: 0.9819 - val_loss: 0.0755\n",
            "Epoch 41/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.9840 - loss: 0.0445 - val_accuracy: 0.9806 - val_loss: 0.0830\n",
            "Epoch 42/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9851 - loss: 0.0469 - val_accuracy: 0.9762 - val_loss: 0.0866\n",
            "Epoch 43/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9866 - loss: 0.0430 - val_accuracy: 0.9825 - val_loss: 0.0726\n",
            "Epoch 44/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.9843 - loss: 0.0436 - val_accuracy: 0.9819 - val_loss: 0.0746\n",
            "Epoch 45/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9857 - loss: 0.0328 - val_accuracy: 0.9794 - val_loss: 0.0768\n",
            "Epoch 1/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - accuracy: 0.8202 - loss: 0.8547 - val_accuracy: 0.9381 - val_loss: 0.2084\n",
            "Epoch 2/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9466 - loss: 0.1765 - val_accuracy: 0.9556 - val_loss: 0.1382\n",
            "Epoch 3/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9524 - loss: 0.1583 - val_accuracy: 0.9581 - val_loss: 0.1338\n",
            "Epoch 4/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9575 - loss: 0.1384 - val_accuracy: 0.9550 - val_loss: 0.1405\n",
            "Epoch 5/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9583 - loss: 0.1319 - val_accuracy: 0.9619 - val_loss: 0.1186\n",
            "Epoch 6/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.9585 - loss: 0.1274 - val_accuracy: 0.9625 - val_loss: 0.1265\n",
            "Epoch 7/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9519 - loss: 0.1482 - val_accuracy: 0.9606 - val_loss: 0.1247\n",
            "Epoch 8/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9600 - loss: 0.1180 - val_accuracy: 0.9581 - val_loss: 0.1230\n",
            "Epoch 9/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.9685 - loss: 0.1084 - val_accuracy: 0.9619 - val_loss: 0.1185\n",
            "Epoch 10/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.9639 - loss: 0.1152 - val_accuracy: 0.9619 - val_loss: 0.1249\n",
            "Epoch 11/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9670 - loss: 0.1005 - val_accuracy: 0.9588 - val_loss: 0.1193\n",
            "Epoch 12/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9656 - loss: 0.1059 - val_accuracy: 0.9631 - val_loss: 0.1161\n",
            "Epoch 13/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.9643 - loss: 0.1055 - val_accuracy: 0.9625 - val_loss: 0.1085\n",
            "Epoch 14/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9645 - loss: 0.1056 - val_accuracy: 0.9613 - val_loss: 0.1107\n",
            "Epoch 15/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9698 - loss: 0.0942 - val_accuracy: 0.9613 - val_loss: 0.1121\n",
            "Epoch 16/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9673 - loss: 0.0946 - val_accuracy: 0.9613 - val_loss: 0.1149\n",
            "Epoch 17/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9740 - loss: 0.0855 - val_accuracy: 0.9594 - val_loss: 0.1181\n",
            "Epoch 18/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.9744 - loss: 0.0816 - val_accuracy: 0.9638 - val_loss: 0.1094\n",
            "Epoch 19/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9709 - loss: 0.0928 - val_accuracy: 0.9631 - val_loss: 0.1115\n",
            "Epoch 20/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9723 - loss: 0.0829 - val_accuracy: 0.9644 - val_loss: 0.1079\n",
            "Epoch 21/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9746 - loss: 0.0698 - val_accuracy: 0.9663 - val_loss: 0.1120\n",
            "Epoch 22/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9719 - loss: 0.0857 - val_accuracy: 0.9631 - val_loss: 0.1062\n",
            "Epoch 23/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9718 - loss: 0.0856 - val_accuracy: 0.9663 - val_loss: 0.1048\n",
            "Epoch 24/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9767 - loss: 0.0715 - val_accuracy: 0.9656 - val_loss: 0.1140\n",
            "Epoch 25/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9796 - loss: 0.0605 - val_accuracy: 0.9594 - val_loss: 0.1036\n",
            "Epoch 26/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9796 - loss: 0.0643 - val_accuracy: 0.9631 - val_loss: 0.1079\n",
            "Epoch 27/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.9791 - loss: 0.0609 - val_accuracy: 0.9681 - val_loss: 0.1012\n",
            "Epoch 28/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9785 - loss: 0.0613 - val_accuracy: 0.9694 - val_loss: 0.1038\n",
            "Epoch 29/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9795 - loss: 0.0646 - val_accuracy: 0.9644 - val_loss: 0.1092\n",
            "Epoch 30/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9815 - loss: 0.0590 - val_accuracy: 0.9675 - val_loss: 0.0980\n",
            "Epoch 31/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9795 - loss: 0.0561 - val_accuracy: 0.9688 - val_loss: 0.0999\n",
            "Epoch 32/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.9808 - loss: 0.0594 - val_accuracy: 0.9681 - val_loss: 0.1021\n",
            "Epoch 33/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9819 - loss: 0.0598 - val_accuracy: 0.9700 - val_loss: 0.1014\n",
            "Epoch 34/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9799 - loss: 0.0606 - val_accuracy: 0.9706 - val_loss: 0.0996\n",
            "Epoch 35/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9833 - loss: 0.0476 - val_accuracy: 0.9656 - val_loss: 0.1344\n",
            "Epoch 36/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9805 - loss: 0.0488 - val_accuracy: 0.9681 - val_loss: 0.1016\n",
            "Epoch 37/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.9832 - loss: 0.0467 - val_accuracy: 0.9700 - val_loss: 0.0961\n",
            "Epoch 38/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.9823 - loss: 0.0539 - val_accuracy: 0.9700 - val_loss: 0.0997\n",
            "Epoch 39/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9870 - loss: 0.0385 - val_accuracy: 0.9694 - val_loss: 0.1216\n",
            "Epoch 40/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9855 - loss: 0.0436 - val_accuracy: 0.9712 - val_loss: 0.0985\n",
            "Epoch 41/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.9877 - loss: 0.0353 - val_accuracy: 0.9688 - val_loss: 0.1075\n",
            "Epoch 42/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9856 - loss: 0.0372 - val_accuracy: 0.9700 - val_loss: 0.1124\n",
            "Epoch 43/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9865 - loss: 0.0410 - val_accuracy: 0.9688 - val_loss: 0.1051\n",
            "Epoch 44/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9894 - loss: 0.0318 - val_accuracy: 0.9744 - val_loss: 0.1143\n",
            "Epoch 45/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.9870 - loss: 0.0314 - val_accuracy: 0.9675 - val_loss: 0.1212\n",
            "Epoch 46/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.9896 - loss: 0.0309 - val_accuracy: 0.9725 - val_loss: 0.1125\n",
            "Epoch 47/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9903 - loss: 0.0294 - val_accuracy: 0.9669 - val_loss: 0.1121\n",
            "Epoch 1/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - accuracy: 0.8003 - loss: 0.8380 - val_accuracy: 0.9481 - val_loss: 0.2037\n",
            "Epoch 2/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9466 - loss: 0.1838 - val_accuracy: 0.9575 - val_loss: 0.1499\n",
            "Epoch 3/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9506 - loss: 0.1496 - val_accuracy: 0.9569 - val_loss: 0.1362\n",
            "Epoch 4/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9542 - loss: 0.1413 - val_accuracy: 0.9588 - val_loss: 0.1424\n",
            "Epoch 5/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.9556 - loss: 0.1384 - val_accuracy: 0.9531 - val_loss: 0.1522\n",
            "Epoch 6/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.9546 - loss: 0.1366 - val_accuracy: 0.9575 - val_loss: 0.1439\n",
            "Epoch 7/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9586 - loss: 0.1238 - val_accuracy: 0.9631 - val_loss: 0.1198\n",
            "Epoch 8/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9611 - loss: 0.1204 - val_accuracy: 0.9613 - val_loss: 0.1202\n",
            "Epoch 9/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.9597 - loss: 0.1236 - val_accuracy: 0.9606 - val_loss: 0.1150\n",
            "Epoch 10/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9635 - loss: 0.1137 - val_accuracy: 0.9631 - val_loss: 0.1066\n",
            "Epoch 11/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9644 - loss: 0.1118 - val_accuracy: 0.9613 - val_loss: 0.1139\n",
            "Epoch 12/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9633 - loss: 0.1091 - val_accuracy: 0.9650 - val_loss: 0.1125\n",
            "Epoch 13/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9678 - loss: 0.1052 - val_accuracy: 0.9650 - val_loss: 0.1087\n",
            "Epoch 14/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.9698 - loss: 0.0946 - val_accuracy: 0.9656 - val_loss: 0.1071\n",
            "Epoch 15/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9720 - loss: 0.0849 - val_accuracy: 0.9675 - val_loss: 0.1048\n",
            "Epoch 16/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9696 - loss: 0.0984 - val_accuracy: 0.9663 - val_loss: 0.1117\n",
            "Epoch 17/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9665 - loss: 0.1058 - val_accuracy: 0.9675 - val_loss: 0.1029\n",
            "Epoch 18/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9720 - loss: 0.0944 - val_accuracy: 0.9688 - val_loss: 0.1012\n",
            "Epoch 19/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.9724 - loss: 0.0846 - val_accuracy: 0.9700 - val_loss: 0.0910\n",
            "Epoch 20/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9723 - loss: 0.0925 - val_accuracy: 0.9681 - val_loss: 0.0959\n",
            "Epoch 21/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9749 - loss: 0.0805 - val_accuracy: 0.9694 - val_loss: 0.0939\n",
            "Epoch 22/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.9735 - loss: 0.0775 - val_accuracy: 0.9700 - val_loss: 0.0930\n",
            "Epoch 23/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.9774 - loss: 0.0734 - val_accuracy: 0.9694 - val_loss: 0.0962\n",
            "Epoch 24/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9770 - loss: 0.0712 - val_accuracy: 0.9719 - val_loss: 0.0903\n",
            "Epoch 25/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9738 - loss: 0.0725 - val_accuracy: 0.9712 - val_loss: 0.0928\n",
            "Epoch 26/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.9779 - loss: 0.0712 - val_accuracy: 0.9719 - val_loss: 0.1010\n",
            "Epoch 27/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9806 - loss: 0.0589 - val_accuracy: 0.9725 - val_loss: 0.0943\n",
            "Epoch 28/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9822 - loss: 0.0625 - val_accuracy: 0.9725 - val_loss: 0.0886\n",
            "Epoch 29/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9817 - loss: 0.0580 - val_accuracy: 0.9744 - val_loss: 0.0902\n",
            "Epoch 30/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9809 - loss: 0.0584 - val_accuracy: 0.9663 - val_loss: 0.1067\n",
            "Epoch 31/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.9803 - loss: 0.0562 - val_accuracy: 0.9681 - val_loss: 0.0991\n",
            "Epoch 32/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.9827 - loss: 0.0530 - val_accuracy: 0.9625 - val_loss: 0.1082\n",
            "Epoch 33/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9790 - loss: 0.0602 - val_accuracy: 0.9725 - val_loss: 0.0982\n",
            "Epoch 34/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9832 - loss: 0.0515 - val_accuracy: 0.9737 - val_loss: 0.0885\n",
            "Epoch 35/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.9791 - loss: 0.0550 - val_accuracy: 0.9737 - val_loss: 0.0842\n",
            "Epoch 36/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9886 - loss: 0.0396 - val_accuracy: 0.9712 - val_loss: 0.0999\n",
            "Epoch 37/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9872 - loss: 0.0431 - val_accuracy: 0.9719 - val_loss: 0.0996\n",
            "Epoch 38/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.9852 - loss: 0.0429 - val_accuracy: 0.9706 - val_loss: 0.0966\n",
            "Epoch 39/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9852 - loss: 0.0466 - val_accuracy: 0.9737 - val_loss: 0.0973\n",
            "Epoch 40/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9842 - loss: 0.0447 - val_accuracy: 0.9712 - val_loss: 0.1041\n",
            "Epoch 41/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9857 - loss: 0.0386 - val_accuracy: 0.9725 - val_loss: 0.0994\n",
            "Epoch 42/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9868 - loss: 0.0372 - val_accuracy: 0.9694 - val_loss: 0.1180\n",
            "Epoch 43/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.9849 - loss: 0.0442 - val_accuracy: 0.9744 - val_loss: 0.0977\n",
            "Epoch 44/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.9873 - loss: 0.0419 - val_accuracy: 0.9719 - val_loss: 0.1147\n",
            "Epoch 45/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9882 - loss: 0.0340 - val_accuracy: 0.9712 - val_loss: 0.0943\n",
            "Epoch 1/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - accuracy: 0.7667 - loss: 0.8911 - val_accuracy: 0.9325 - val_loss: 0.2279\n",
            "Epoch 2/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9478 - loss: 0.1861 - val_accuracy: 0.9488 - val_loss: 0.1747\n",
            "Epoch 3/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9537 - loss: 0.1548 - val_accuracy: 0.9525 - val_loss: 0.1480\n",
            "Epoch 4/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - accuracy: 0.9568 - loss: 0.1378 - val_accuracy: 0.9569 - val_loss: 0.1387\n",
            "Epoch 5/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9564 - loss: 0.1288 - val_accuracy: 0.9425 - val_loss: 0.1738\n",
            "Epoch 6/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9507 - loss: 0.1427 - val_accuracy: 0.9613 - val_loss: 0.1316\n",
            "Epoch 7/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9615 - loss: 0.1187 - val_accuracy: 0.9550 - val_loss: 0.1410\n",
            "Epoch 8/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9570 - loss: 0.1250 - val_accuracy: 0.9619 - val_loss: 0.1274\n",
            "Epoch 9/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.9622 - loss: 0.1267 - val_accuracy: 0.9606 - val_loss: 0.1199\n",
            "Epoch 10/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.9644 - loss: 0.1044 - val_accuracy: 0.9625 - val_loss: 0.1183\n",
            "Epoch 11/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9655 - loss: 0.1079 - val_accuracy: 0.9600 - val_loss: 0.1264\n",
            "Epoch 12/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.9625 - loss: 0.1061 - val_accuracy: 0.9681 - val_loss: 0.1222\n",
            "Epoch 13/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.9679 - loss: 0.0938 - val_accuracy: 0.9606 - val_loss: 0.1180\n",
            "Epoch 14/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9703 - loss: 0.0901 - val_accuracy: 0.9638 - val_loss: 0.1129\n",
            "Epoch 15/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9726 - loss: 0.0889 - val_accuracy: 0.9619 - val_loss: 0.1234\n",
            "Epoch 16/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.9709 - loss: 0.0954 - val_accuracy: 0.9619 - val_loss: 0.1152\n",
            "Epoch 17/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.9743 - loss: 0.0843 - val_accuracy: 0.9613 - val_loss: 0.1223\n",
            "Epoch 18/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9714 - loss: 0.0855 - val_accuracy: 0.9638 - val_loss: 0.1115\n",
            "Epoch 19/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9711 - loss: 0.0900 - val_accuracy: 0.9650 - val_loss: 0.1055\n",
            "Epoch 20/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.9708 - loss: 0.0903 - val_accuracy: 0.9663 - val_loss: 0.1119\n",
            "Epoch 21/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.9705 - loss: 0.0819 - val_accuracy: 0.9694 - val_loss: 0.0973\n",
            "Epoch 22/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9724 - loss: 0.0805 - val_accuracy: 0.9644 - val_loss: 0.1002\n",
            "Epoch 23/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9777 - loss: 0.0722 - val_accuracy: 0.9700 - val_loss: 0.1001\n",
            "Epoch 24/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.9757 - loss: 0.0658 - val_accuracy: 0.9700 - val_loss: 0.1045\n",
            "Epoch 25/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.9718 - loss: 0.0796 - val_accuracy: 0.9669 - val_loss: 0.0988\n",
            "Epoch 26/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9753 - loss: 0.0722 - val_accuracy: 0.9719 - val_loss: 0.0959\n",
            "Epoch 27/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9766 - loss: 0.0704 - val_accuracy: 0.9681 - val_loss: 0.1009\n",
            "Epoch 28/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.9765 - loss: 0.0713 - val_accuracy: 0.9712 - val_loss: 0.0961\n",
            "Epoch 29/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.9773 - loss: 0.0671 - val_accuracy: 0.9619 - val_loss: 0.1028\n",
            "Epoch 30/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9783 - loss: 0.0672 - val_accuracy: 0.9712 - val_loss: 0.0924\n",
            "Epoch 31/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.9785 - loss: 0.0599 - val_accuracy: 0.9688 - val_loss: 0.0918\n",
            "Epoch 32/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.9775 - loss: 0.0664 - val_accuracy: 0.9706 - val_loss: 0.0960\n",
            "Epoch 33/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9790 - loss: 0.0597 - val_accuracy: 0.9694 - val_loss: 0.0935\n",
            "Epoch 34/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9835 - loss: 0.0517 - val_accuracy: 0.9731 - val_loss: 0.0934\n",
            "Epoch 35/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.9834 - loss: 0.0490 - val_accuracy: 0.9706 - val_loss: 0.0952\n",
            "Epoch 36/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.9834 - loss: 0.0511 - val_accuracy: 0.9650 - val_loss: 0.1206\n",
            "Epoch 37/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9819 - loss: 0.0482 - val_accuracy: 0.9725 - val_loss: 0.0945\n",
            "Epoch 38/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9829 - loss: 0.0487 - val_accuracy: 0.9775 - val_loss: 0.0829\n",
            "Epoch 39/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.9845 - loss: 0.0416 - val_accuracy: 0.9706 - val_loss: 0.0952\n",
            "Epoch 40/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9860 - loss: 0.0417 - val_accuracy: 0.9681 - val_loss: 0.1041\n",
            "Epoch 41/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9848 - loss: 0.0410 - val_accuracy: 0.9700 - val_loss: 0.1110\n",
            "Epoch 42/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9860 - loss: 0.0401 - val_accuracy: 0.9769 - val_loss: 0.0863\n",
            "Epoch 43/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9872 - loss: 0.0387 - val_accuracy: 0.9688 - val_loss: 0.1039\n",
            "Epoch 44/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.9873 - loss: 0.0407 - val_accuracy: 0.9663 - val_loss: 0.1031\n",
            "Epoch 45/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9845 - loss: 0.0409 - val_accuracy: 0.9719 - val_loss: 0.0975\n",
            "Epoch 46/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9872 - loss: 0.0345 - val_accuracy: 0.9756 - val_loss: 0.0918\n",
            "Epoch 47/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9877 - loss: 0.0313 - val_accuracy: 0.9750 - val_loss: 0.0916\n",
            "Epoch 48/100\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.9889 - loss: 0.0330 - val_accuracy: 0.9737 - val_loss: 0.1099\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.impute import KNNImputer\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Bidirectional, GRU, BatchNormalization, LayerNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "def load_and_preprocess():\n",
        "    df = pd.read_csv(\"hacktrain.csv\")\n",
        "    df.drop(columns=['ID'], inplace=True)\n",
        "\n",
        "    imputer = KNNImputer(n_neighbors=3)\n",
        "    numeric_cols = df.select_dtypes(include=np.number).columns\n",
        "    df[numeric_cols] = imputer.fit_transform(df[numeric_cols])\n",
        "\n",
        "    label_encoder = LabelEncoder()\n",
        "    df['class'] = label_encoder.fit_transform(df['class'])\n",
        "\n",
        "    X = df.drop(columns=['class']).values\n",
        "    y = df['class'].values\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X = scaler.fit_transform(X)\n",
        "    X = X.reshape(X.shape[0], X.shape[1], 1)\n",
        "    y = to_categorical(y)\n",
        "    return X, y, label_encoder, scaler, imputer\n",
        "\n",
        "def create_bigru_model(input_shape, num_classes):\n",
        "    model = Sequential([\n",
        "        Bidirectional(GRU(256, return_sequences=True, kernel_regularizer=l2(0.001)), input_shape=input_shape),\n",
        "        LayerNormalization(),\n",
        "        Dropout(0.3),\n",
        "        Bidirectional(GRU(128, return_sequences=True, kernel_regularizer=l2(0.001))),\n",
        "        LayerNormalization(),\n",
        "        Dropout(0.3),\n",
        "        Bidirectional(GRU(64)),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.2),\n",
        "        Dense(256, activation='relu', kernel_regularizer=l2(0.001)),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.2),\n",
        "        Dense(128, activation='relu', kernel_regularizer=l2(0.001)),\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer=Adam(learning_rate=0.0002),\n",
        "                 loss='categorical_crossentropy',\n",
        "                 metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def kfold_cross_validation(X, y, n_splits=5, epochs=50, batch_size=64):\n",
        "    kfold = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "    fold_no = 1\n",
        "    histories = []\n",
        "    y_labels = np.argmax(y, axis=1)\n",
        "\n",
        "    for train_idx, val_idx in kfold.split(X, y_labels):\n",
        "        model = create_bigru_model((X.shape[1], X.shape[2]), y.shape[1])\n",
        "        es = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
        "        lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n",
        "\n",
        "        history = model.fit(\n",
        "            X[train_idx], y[train_idx],\n",
        "            validation_data=(X[val_idx], y[val_idx]),\n",
        "            epochs=epochs,\n",
        "            batch_size=batch_size,\n",
        "            callbacks=[es, lr_reducer],\n",
        "            verbose=1\n",
        "        )\n",
        "        histories.append(history)\n",
        "        fold_no += 1\n",
        "\n",
        "    return model, histories\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    X, y, label_encoder, scaler, imputer = load_and_preprocess()\n",
        "    trained_model, _ = kfold_cross_validation(X, y)\n",
        "\n",
        "    test_data = pd.read_csv(\"hacktest.csv\")\n",
        "    ID = test_data['ID']\n",
        "    test_data.drop(['ID'], axis=1, inplace=True)\n",
        "\n",
        "    numeric_cols = test_data.select_dtypes(include=np.number).columns\n",
        "    test_data[numeric_cols] = imputer.transform(test_data[numeric_cols])\n",
        "\n",
        "    X_test = scaler.transform(test_data.values)\n",
        "    X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
        "\n",
        "    y_pred = np.argmax(trained_model.predict(X_test), axis=1)\n",
        "    y_decoded = label_encoder.inverse_transform(y_pred)\n",
        "\n",
        "    pd.DataFrame({'ID': ID, 'class': y_decoded}).to_csv(\"improved_bigru.csv\", index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_8vaLkqCV2y",
        "outputId": "e3ff1f9b-2d00-443d-c11e-4feb9c2d6197"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - accuracy: 0.5863 - loss: 2.3474 - val_accuracy: 0.9038 - val_loss: 1.4492 - learning_rate: 2.0000e-04\n",
            "Epoch 2/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - accuracy: 0.9010 - loss: 1.4200 - val_accuracy: 0.9219 - val_loss: 1.2519 - learning_rate: 2.0000e-04\n",
            "Epoch 3/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.9297 - loss: 1.2284 - val_accuracy: 0.9456 - val_loss: 1.1052 - learning_rate: 2.0000e-04\n",
            "Epoch 4/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9396 - loss: 1.1246 - val_accuracy: 0.9431 - val_loss: 1.0835 - learning_rate: 2.0000e-04\n",
            "Epoch 5/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.9464 - loss: 1.0487 - val_accuracy: 0.9550 - val_loss: 0.9644 - learning_rate: 2.0000e-04\n",
            "Epoch 6/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.9457 - loss: 0.9801 - val_accuracy: 0.9544 - val_loss: 0.9147 - learning_rate: 2.0000e-04\n",
            "Epoch 7/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.9448 - loss: 0.9433 - val_accuracy: 0.9525 - val_loss: 0.8768 - learning_rate: 2.0000e-04\n",
            "Epoch 8/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - accuracy: 0.9498 - loss: 0.8847 - val_accuracy: 0.9575 - val_loss: 0.8302 - learning_rate: 2.0000e-04\n",
            "Epoch 9/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9466 - loss: 0.8570 - val_accuracy: 0.9569 - val_loss: 0.8068 - learning_rate: 2.0000e-04\n",
            "Epoch 10/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9545 - loss: 0.8159 - val_accuracy: 0.9569 - val_loss: 0.7724 - learning_rate: 2.0000e-04\n",
            "Epoch 11/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.9565 - loss: 0.7751 - val_accuracy: 0.9581 - val_loss: 0.7436 - learning_rate: 2.0000e-04\n",
            "Epoch 12/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.9607 - loss: 0.7391 - val_accuracy: 0.9600 - val_loss: 0.7103 - learning_rate: 2.0000e-04\n",
            "Epoch 13/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9598 - loss: 0.7198 - val_accuracy: 0.9613 - val_loss: 0.6814 - learning_rate: 2.0000e-04\n",
            "Epoch 14/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9592 - loss: 0.6828 - val_accuracy: 0.9631 - val_loss: 0.6561 - learning_rate: 2.0000e-04\n",
            "Epoch 15/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9624 - loss: 0.6552 - val_accuracy: 0.9625 - val_loss: 0.6371 - learning_rate: 2.0000e-04\n",
            "Epoch 16/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.9605 - loss: 0.6289 - val_accuracy: 0.9563 - val_loss: 0.6277 - learning_rate: 2.0000e-04\n",
            "Epoch 17/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.9652 - loss: 0.5942 - val_accuracy: 0.9656 - val_loss: 0.5866 - learning_rate: 2.0000e-04\n",
            "Epoch 18/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9677 - loss: 0.5766 - val_accuracy: 0.9663 - val_loss: 0.5686 - learning_rate: 2.0000e-04\n",
            "Epoch 19/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9606 - loss: 0.5734 - val_accuracy: 0.9669 - val_loss: 0.5409 - learning_rate: 2.0000e-04\n",
            "Epoch 20/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.9657 - loss: 0.5450 - val_accuracy: 0.9694 - val_loss: 0.5284 - learning_rate: 2.0000e-04\n",
            "Epoch 21/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9658 - loss: 0.5236 - val_accuracy: 0.9650 - val_loss: 0.5150 - learning_rate: 2.0000e-04\n",
            "Epoch 22/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.9690 - loss: 0.4945 - val_accuracy: 0.9700 - val_loss: 0.4906 - learning_rate: 2.0000e-04\n",
            "Epoch 23/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9741 - loss: 0.4715 - val_accuracy: 0.9688 - val_loss: 0.4752 - learning_rate: 2.0000e-04\n",
            "Epoch 24/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9708 - loss: 0.4615 - val_accuracy: 0.9694 - val_loss: 0.4687 - learning_rate: 2.0000e-04\n",
            "Epoch 25/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9687 - loss: 0.4539 - val_accuracy: 0.9669 - val_loss: 0.4577 - learning_rate: 2.0000e-04\n",
            "Epoch 26/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.9694 - loss: 0.4318 - val_accuracy: 0.9669 - val_loss: 0.4470 - learning_rate: 2.0000e-04\n",
            "Epoch 27/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.9684 - loss: 0.4167 - val_accuracy: 0.9669 - val_loss: 0.4265 - learning_rate: 2.0000e-04\n",
            "Epoch 28/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9687 - loss: 0.4099 - val_accuracy: 0.9700 - val_loss: 0.4160 - learning_rate: 2.0000e-04\n",
            "Epoch 29/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9775 - loss: 0.3835 - val_accuracy: 0.9700 - val_loss: 0.3873 - learning_rate: 2.0000e-04\n",
            "Epoch 30/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9763 - loss: 0.3737 - val_accuracy: 0.9675 - val_loss: 0.3952 - learning_rate: 2.0000e-04\n",
            "Epoch 31/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9727 - loss: 0.3681 - val_accuracy: 0.9725 - val_loss: 0.3705 - learning_rate: 2.0000e-04\n",
            "Epoch 32/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - accuracy: 0.9750 - loss: 0.3492 - val_accuracy: 0.9706 - val_loss: 0.3635 - learning_rate: 2.0000e-04\n",
            "Epoch 33/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9709 - loss: 0.3487 - val_accuracy: 0.9719 - val_loss: 0.3483 - learning_rate: 2.0000e-04\n",
            "Epoch 34/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9769 - loss: 0.3236 - val_accuracy: 0.9681 - val_loss: 0.3477 - learning_rate: 2.0000e-04\n",
            "Epoch 35/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9763 - loss: 0.3190 - val_accuracy: 0.9712 - val_loss: 0.3407 - learning_rate: 2.0000e-04\n",
            "Epoch 36/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.9796 - loss: 0.3046 - val_accuracy: 0.9688 - val_loss: 0.3266 - learning_rate: 2.0000e-04\n",
            "Epoch 37/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.9773 - loss: 0.2942 - val_accuracy: 0.9681 - val_loss: 0.3199 - learning_rate: 2.0000e-04\n",
            "Epoch 38/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9772 - loss: 0.2937 - val_accuracy: 0.9731 - val_loss: 0.3111 - learning_rate: 2.0000e-04\n",
            "Epoch 39/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9799 - loss: 0.2731 - val_accuracy: 0.9712 - val_loss: 0.2998 - learning_rate: 2.0000e-04\n",
            "Epoch 40/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9784 - loss: 0.2721 - val_accuracy: 0.9719 - val_loss: 0.2892 - learning_rate: 2.0000e-04\n",
            "Epoch 41/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9811 - loss: 0.2575 - val_accuracy: 0.9694 - val_loss: 0.2988 - learning_rate: 2.0000e-04\n",
            "Epoch 42/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - accuracy: 0.9788 - loss: 0.2580 - val_accuracy: 0.9731 - val_loss: 0.2847 - learning_rate: 2.0000e-04\n",
            "Epoch 43/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9793 - loss: 0.2415 - val_accuracy: 0.9719 - val_loss: 0.2726 - learning_rate: 2.0000e-04\n",
            "Epoch 44/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9799 - loss: 0.2460 - val_accuracy: 0.9694 - val_loss: 0.2793 - learning_rate: 2.0000e-04\n",
            "Epoch 45/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9840 - loss: 0.2268 - val_accuracy: 0.9750 - val_loss: 0.2643 - learning_rate: 2.0000e-04\n",
            "Epoch 46/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9840 - loss: 0.2186 - val_accuracy: 0.9644 - val_loss: 0.2667 - learning_rate: 2.0000e-04\n",
            "Epoch 47/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - accuracy: 0.9799 - loss: 0.2213 - val_accuracy: 0.9694 - val_loss: 0.2575 - learning_rate: 2.0000e-04\n",
            "Epoch 48/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9825 - loss: 0.2103 - val_accuracy: 0.9712 - val_loss: 0.2505 - learning_rate: 2.0000e-04\n",
            "Epoch 49/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9841 - loss: 0.2035 - val_accuracy: 0.9719 - val_loss: 0.2467 - learning_rate: 2.0000e-04\n",
            "Epoch 50/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9842 - loss: 0.1943 - val_accuracy: 0.9725 - val_loss: 0.2487 - learning_rate: 2.0000e-04\n",
            "Epoch 1/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 30ms/step - accuracy: 0.6607 - loss: 2.1744 - val_accuracy: 0.9025 - val_loss: 1.4262 - learning_rate: 2.0000e-04\n",
            "Epoch 2/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.8998 - loss: 1.4128 - val_accuracy: 0.9388 - val_loss: 1.2206 - learning_rate: 2.0000e-04\n",
            "Epoch 3/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9260 - loss: 1.2348 - val_accuracy: 0.9431 - val_loss: 1.1242 - learning_rate: 2.0000e-04\n",
            "Epoch 4/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 0.9353 - loss: 1.1313 - val_accuracy: 0.9606 - val_loss: 1.0036 - learning_rate: 2.0000e-04\n",
            "Epoch 5/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.9345 - loss: 1.0622 - val_accuracy: 0.9625 - val_loss: 0.9463 - learning_rate: 2.0000e-04\n",
            "Epoch 6/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9421 - loss: 0.9979 - val_accuracy: 0.9631 - val_loss: 0.8958 - learning_rate: 2.0000e-04\n",
            "Epoch 7/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9490 - loss: 0.9419 - val_accuracy: 0.9675 - val_loss: 0.8561 - learning_rate: 2.0000e-04\n",
            "Epoch 8/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.9567 - loss: 0.8855 - val_accuracy: 0.9650 - val_loss: 0.8342 - learning_rate: 2.0000e-04\n",
            "Epoch 9/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - accuracy: 0.9497 - loss: 0.8654 - val_accuracy: 0.9706 - val_loss: 0.7834 - learning_rate: 2.0000e-04\n",
            "Epoch 10/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9527 - loss: 0.8223 - val_accuracy: 0.9650 - val_loss: 0.7615 - learning_rate: 2.0000e-04\n",
            "Epoch 11/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.9504 - loss: 0.7970 - val_accuracy: 0.9650 - val_loss: 0.7500 - learning_rate: 2.0000e-04\n",
            "Epoch 12/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.9511 - loss: 0.7642 - val_accuracy: 0.9656 - val_loss: 0.7184 - learning_rate: 2.0000e-04\n",
            "Epoch 13/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9504 - loss: 0.7495 - val_accuracy: 0.9681 - val_loss: 0.6749 - learning_rate: 2.0000e-04\n",
            "Epoch 14/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.9570 - loss: 0.6955 - val_accuracy: 0.9750 - val_loss: 0.6478 - learning_rate: 2.0000e-04\n",
            "Epoch 15/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9652 - loss: 0.6677 - val_accuracy: 0.9663 - val_loss: 0.6432 - learning_rate: 2.0000e-04\n",
            "Epoch 16/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9652 - loss: 0.6375 - val_accuracy: 0.9725 - val_loss: 0.6053 - learning_rate: 2.0000e-04\n",
            "Epoch 17/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - accuracy: 0.9630 - loss: 0.6230 - val_accuracy: 0.9731 - val_loss: 0.5920 - learning_rate: 2.0000e-04\n",
            "Epoch 18/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.9673 - loss: 0.5964 - val_accuracy: 0.9712 - val_loss: 0.5704 - learning_rate: 2.0000e-04\n",
            "Epoch 19/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9591 - loss: 0.5838 - val_accuracy: 0.9744 - val_loss: 0.5444 - learning_rate: 2.0000e-04\n",
            "Epoch 20/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - accuracy: 0.9666 - loss: 0.5517 - val_accuracy: 0.9744 - val_loss: 0.5296 - learning_rate: 2.0000e-04\n",
            "Epoch 21/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - accuracy: 0.9681 - loss: 0.5299 - val_accuracy: 0.9725 - val_loss: 0.5090 - learning_rate: 2.0000e-04\n",
            "Epoch 22/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.9675 - loss: 0.5200 - val_accuracy: 0.9750 - val_loss: 0.4900 - learning_rate: 2.0000e-04\n",
            "Epoch 23/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9645 - loss: 0.5030 - val_accuracy: 0.9750 - val_loss: 0.4779 - learning_rate: 2.0000e-04\n",
            "Epoch 24/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - accuracy: 0.9656 - loss: 0.4880 - val_accuracy: 0.9750 - val_loss: 0.4598 - learning_rate: 2.0000e-04\n",
            "Epoch 25/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9716 - loss: 0.4651 - val_accuracy: 0.9731 - val_loss: 0.4561 - learning_rate: 2.0000e-04\n",
            "Epoch 26/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9733 - loss: 0.4446 - val_accuracy: 0.9756 - val_loss: 0.4362 - learning_rate: 2.0000e-04\n",
            "Epoch 27/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9740 - loss: 0.4260 - val_accuracy: 0.9781 - val_loss: 0.4197 - learning_rate: 2.0000e-04\n",
            "Epoch 28/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.9721 - loss: 0.4226 - val_accuracy: 0.9756 - val_loss: 0.4089 - learning_rate: 2.0000e-04\n",
            "Epoch 29/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.9721 - loss: 0.4085 - val_accuracy: 0.9719 - val_loss: 0.4015 - learning_rate: 2.0000e-04\n",
            "Epoch 30/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.9739 - loss: 0.3893 - val_accuracy: 0.9744 - val_loss: 0.3794 - learning_rate: 2.0000e-04\n",
            "Epoch 31/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.9735 - loss: 0.3829 - val_accuracy: 0.9794 - val_loss: 0.3665 - learning_rate: 2.0000e-04\n",
            "Epoch 32/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9711 - loss: 0.3734 - val_accuracy: 0.9787 - val_loss: 0.3552 - learning_rate: 2.0000e-04\n",
            "Epoch 33/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.9735 - loss: 0.3503 - val_accuracy: 0.9825 - val_loss: 0.3438 - learning_rate: 2.0000e-04\n",
            "Epoch 34/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9752 - loss: 0.3408 - val_accuracy: 0.9756 - val_loss: 0.3387 - learning_rate: 2.0000e-04\n",
            "Epoch 35/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9732 - loss: 0.3345 - val_accuracy: 0.9794 - val_loss: 0.3316 - learning_rate: 2.0000e-04\n",
            "Epoch 36/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.9736 - loss: 0.3199 - val_accuracy: 0.9769 - val_loss: 0.3235 - learning_rate: 2.0000e-04\n",
            "Epoch 37/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.9749 - loss: 0.3142 - val_accuracy: 0.9794 - val_loss: 0.3063 - learning_rate: 2.0000e-04\n",
            "Epoch 38/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.9752 - loss: 0.3011 - val_accuracy: 0.9775 - val_loss: 0.3020 - learning_rate: 2.0000e-04\n",
            "Epoch 39/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9741 - loss: 0.2979 - val_accuracy: 0.9787 - val_loss: 0.2932 - learning_rate: 2.0000e-04\n",
            "Epoch 40/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.9814 - loss: 0.2748 - val_accuracy: 0.9781 - val_loss: 0.2887 - learning_rate: 2.0000e-04\n",
            "Epoch 41/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9812 - loss: 0.2642 - val_accuracy: 0.9787 - val_loss: 0.2803 - learning_rate: 2.0000e-04\n",
            "Epoch 42/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.9790 - loss: 0.2608 - val_accuracy: 0.9819 - val_loss: 0.2674 - learning_rate: 2.0000e-04\n",
            "Epoch 43/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - accuracy: 0.9776 - loss: 0.2633 - val_accuracy: 0.9806 - val_loss: 0.2636 - learning_rate: 2.0000e-04\n",
            "Epoch 44/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9804 - loss: 0.2430 - val_accuracy: 0.9775 - val_loss: 0.2577 - learning_rate: 2.0000e-04\n",
            "Epoch 45/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9799 - loss: 0.2363 - val_accuracy: 0.9744 - val_loss: 0.2617 - learning_rate: 2.0000e-04\n",
            "Epoch 46/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.9774 - loss: 0.2371 - val_accuracy: 0.9787 - val_loss: 0.2520 - learning_rate: 2.0000e-04\n",
            "Epoch 47/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9786 - loss: 0.2291 - val_accuracy: 0.9806 - val_loss: 0.2505 - learning_rate: 2.0000e-04\n",
            "Epoch 48/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - accuracy: 0.9796 - loss: 0.2187 - val_accuracy: 0.9775 - val_loss: 0.2389 - learning_rate: 2.0000e-04\n",
            "Epoch 49/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9790 - loss: 0.2168 - val_accuracy: 0.9787 - val_loss: 0.2299 - learning_rate: 2.0000e-04\n",
            "Epoch 50/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9811 - loss: 0.2102 - val_accuracy: 0.9794 - val_loss: 0.2341 - learning_rate: 2.0000e-04\n",
            "Epoch 1/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 0.4806 - loss: 2.7195 - val_accuracy: 0.8512 - val_loss: 1.5235 - learning_rate: 2.0000e-04\n",
            "Epoch 2/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.9071 - loss: 1.4346 - val_accuracy: 0.9194 - val_loss: 1.2678 - learning_rate: 2.0000e-04\n",
            "Epoch 3/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9270 - loss: 1.2379 - val_accuracy: 0.9388 - val_loss: 1.1370 - learning_rate: 2.0000e-04\n",
            "Epoch 4/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - accuracy: 0.9372 - loss: 1.1466 - val_accuracy: 0.9438 - val_loss: 1.0600 - learning_rate: 2.0000e-04\n",
            "Epoch 5/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9366 - loss: 1.0777 - val_accuracy: 0.9525 - val_loss: 0.9786 - learning_rate: 2.0000e-04\n",
            "Epoch 6/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.9456 - loss: 1.0042 - val_accuracy: 0.9525 - val_loss: 0.9378 - learning_rate: 2.0000e-04\n",
            "Epoch 7/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.9493 - loss: 0.9503 - val_accuracy: 0.9544 - val_loss: 0.8892 - learning_rate: 2.0000e-04\n",
            "Epoch 8/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - accuracy: 0.9536 - loss: 0.8831 - val_accuracy: 0.9556 - val_loss: 0.8541 - learning_rate: 2.0000e-04\n",
            "Epoch 9/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - accuracy: 0.9511 - loss: 0.8666 - val_accuracy: 0.9594 - val_loss: 0.8199 - learning_rate: 2.0000e-04\n",
            "Epoch 10/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9541 - loss: 0.8334 - val_accuracy: 0.9588 - val_loss: 0.7770 - learning_rate: 2.0000e-04\n",
            "Epoch 11/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9480 - loss: 0.8141 - val_accuracy: 0.9588 - val_loss: 0.7632 - learning_rate: 2.0000e-04\n",
            "Epoch 12/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.9566 - loss: 0.7659 - val_accuracy: 0.9638 - val_loss: 0.7149 - learning_rate: 2.0000e-04\n",
            "Epoch 13/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - accuracy: 0.9554 - loss: 0.7287 - val_accuracy: 0.9575 - val_loss: 0.7083 - learning_rate: 2.0000e-04\n",
            "Epoch 14/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - accuracy: 0.9547 - loss: 0.7020 - val_accuracy: 0.9650 - val_loss: 0.6651 - learning_rate: 2.0000e-04\n",
            "Epoch 15/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9579 - loss: 0.6668 - val_accuracy: 0.9650 - val_loss: 0.6403 - learning_rate: 2.0000e-04\n",
            "Epoch 16/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.9586 - loss: 0.6468 - val_accuracy: 0.9638 - val_loss: 0.6351 - learning_rate: 2.0000e-04\n",
            "Epoch 17/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9608 - loss: 0.6185 - val_accuracy: 0.9650 - val_loss: 0.5975 - learning_rate: 2.0000e-04\n",
            "Epoch 18/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - accuracy: 0.9602 - loss: 0.6060 - val_accuracy: 0.9669 - val_loss: 0.5793 - learning_rate: 2.0000e-04\n",
            "Epoch 19/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9642 - loss: 0.5816 - val_accuracy: 0.9631 - val_loss: 0.5671 - learning_rate: 2.0000e-04\n",
            "Epoch 20/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9603 - loss: 0.5637 - val_accuracy: 0.9606 - val_loss: 0.5454 - learning_rate: 2.0000e-04\n",
            "Epoch 21/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9650 - loss: 0.5320 - val_accuracy: 0.9650 - val_loss: 0.5231 - learning_rate: 2.0000e-04\n",
            "Epoch 22/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9667 - loss: 0.5154 - val_accuracy: 0.9638 - val_loss: 0.5096 - learning_rate: 2.0000e-04\n",
            "Epoch 23/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - accuracy: 0.9677 - loss: 0.4951 - val_accuracy: 0.9681 - val_loss: 0.4844 - learning_rate: 2.0000e-04\n",
            "Epoch 24/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.9668 - loss: 0.4793 - val_accuracy: 0.9575 - val_loss: 0.4922 - learning_rate: 2.0000e-04\n",
            "Epoch 25/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9679 - loss: 0.4578 - val_accuracy: 0.9663 - val_loss: 0.4617 - learning_rate: 2.0000e-04\n",
            "Epoch 26/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.9696 - loss: 0.4427 - val_accuracy: 0.9663 - val_loss: 0.4508 - learning_rate: 2.0000e-04\n",
            "Epoch 27/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 0.9719 - loss: 0.4271 - val_accuracy: 0.9675 - val_loss: 0.4320 - learning_rate: 2.0000e-04\n",
            "Epoch 28/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9705 - loss: 0.4189 - val_accuracy: 0.9606 - val_loss: 0.4227 - learning_rate: 2.0000e-04\n",
            "Epoch 29/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9709 - loss: 0.3997 - val_accuracy: 0.9594 - val_loss: 0.4143 - learning_rate: 2.0000e-04\n",
            "Epoch 30/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.9680 - loss: 0.3854 - val_accuracy: 0.9681 - val_loss: 0.3934 - learning_rate: 2.0000e-04\n",
            "Epoch 31/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9690 - loss: 0.3768 - val_accuracy: 0.9638 - val_loss: 0.3951 - learning_rate: 2.0000e-04\n",
            "Epoch 32/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - accuracy: 0.9711 - loss: 0.3590 - val_accuracy: 0.9706 - val_loss: 0.3725 - learning_rate: 2.0000e-04\n",
            "Epoch 33/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9686 - loss: 0.3545 - val_accuracy: 0.9700 - val_loss: 0.3532 - learning_rate: 2.0000e-04\n",
            "Epoch 34/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9745 - loss: 0.3363 - val_accuracy: 0.9650 - val_loss: 0.3478 - learning_rate: 2.0000e-04\n",
            "Epoch 35/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.9704 - loss: 0.3381 - val_accuracy: 0.9700 - val_loss: 0.3431 - learning_rate: 2.0000e-04\n",
            "Epoch 36/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9739 - loss: 0.3172 - val_accuracy: 0.9669 - val_loss: 0.3331 - learning_rate: 2.0000e-04\n",
            "Epoch 37/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 0.9715 - loss: 0.3174 - val_accuracy: 0.9663 - val_loss: 0.3413 - learning_rate: 2.0000e-04\n",
            "Epoch 38/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.9756 - loss: 0.2937 - val_accuracy: 0.9675 - val_loss: 0.3133 - learning_rate: 2.0000e-04\n",
            "Epoch 39/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9755 - loss: 0.2866 - val_accuracy: 0.9656 - val_loss: 0.3152 - learning_rate: 2.0000e-04\n",
            "Epoch 40/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.9766 - loss: 0.2752 - val_accuracy: 0.9650 - val_loss: 0.3130 - learning_rate: 2.0000e-04\n",
            "Epoch 41/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - accuracy: 0.9733 - loss: 0.2751 - val_accuracy: 0.9694 - val_loss: 0.2942 - learning_rate: 2.0000e-04\n",
            "Epoch 42/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9788 - loss: 0.2580 - val_accuracy: 0.9712 - val_loss: 0.2838 - learning_rate: 2.0000e-04\n",
            "Epoch 43/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9726 - loss: 0.2613 - val_accuracy: 0.9675 - val_loss: 0.2807 - learning_rate: 2.0000e-04\n",
            "Epoch 44/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9804 - loss: 0.2438 - val_accuracy: 0.9706 - val_loss: 0.2686 - learning_rate: 2.0000e-04\n",
            "Epoch 45/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.9795 - loss: 0.2393 - val_accuracy: 0.9650 - val_loss: 0.2802 - learning_rate: 2.0000e-04\n",
            "Epoch 46/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - accuracy: 0.9759 - loss: 0.2338 - val_accuracy: 0.9688 - val_loss: 0.2655 - learning_rate: 2.0000e-04\n",
            "Epoch 47/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9806 - loss: 0.2280 - val_accuracy: 0.9700 - val_loss: 0.2612 - learning_rate: 2.0000e-04\n",
            "Epoch 48/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9828 - loss: 0.2133 - val_accuracy: 0.9712 - val_loss: 0.2545 - learning_rate: 2.0000e-04\n",
            "Epoch 49/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9774 - loss: 0.2154 - val_accuracy: 0.9712 - val_loss: 0.2481 - learning_rate: 2.0000e-04\n",
            "Epoch 50/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9823 - loss: 0.2024 - val_accuracy: 0.9737 - val_loss: 0.2489 - learning_rate: 2.0000e-04\n",
            "Epoch 1/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 32ms/step - accuracy: 0.4708 - loss: 2.7072 - val_accuracy: 0.8838 - val_loss: 1.4864 - learning_rate: 2.0000e-04\n",
            "Epoch 2/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - accuracy: 0.8950 - loss: 1.4432 - val_accuracy: 0.9181 - val_loss: 1.2923 - learning_rate: 2.0000e-04\n",
            "Epoch 3/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.9206 - loss: 1.2687 - val_accuracy: 0.9400 - val_loss: 1.1686 - learning_rate: 2.0000e-04\n",
            "Epoch 4/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9284 - loss: 1.1677 - val_accuracy: 0.9538 - val_loss: 1.0576 - learning_rate: 2.0000e-04\n",
            "Epoch 5/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9420 - loss: 1.0770 - val_accuracy: 0.9531 - val_loss: 0.9919 - learning_rate: 2.0000e-04\n",
            "Epoch 6/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.9399 - loss: 1.0169 - val_accuracy: 0.9575 - val_loss: 0.9398 - learning_rate: 2.0000e-04\n",
            "Epoch 7/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9402 - loss: 0.9669 - val_accuracy: 0.9588 - val_loss: 0.9037 - learning_rate: 2.0000e-04\n",
            "Epoch 8/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9528 - loss: 0.9155 - val_accuracy: 0.9569 - val_loss: 0.8860 - learning_rate: 2.0000e-04\n",
            "Epoch 9/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.9556 - loss: 0.8669 - val_accuracy: 0.9600 - val_loss: 0.8387 - learning_rate: 2.0000e-04\n",
            "Epoch 10/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.9578 - loss: 0.8248 - val_accuracy: 0.9606 - val_loss: 0.7969 - learning_rate: 2.0000e-04\n",
            "Epoch 11/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 0.9541 - loss: 0.7940 - val_accuracy: 0.9600 - val_loss: 0.7616 - learning_rate: 2.0000e-04\n",
            "Epoch 12/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.9491 - loss: 0.7826 - val_accuracy: 0.9650 - val_loss: 0.7418 - learning_rate: 2.0000e-04\n",
            "Epoch 13/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9561 - loss: 0.7387 - val_accuracy: 0.9631 - val_loss: 0.7155 - learning_rate: 2.0000e-04\n",
            "Epoch 14/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9615 - loss: 0.6971 - val_accuracy: 0.9663 - val_loss: 0.6843 - learning_rate: 2.0000e-04\n",
            "Epoch 15/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 0.9557 - loss: 0.6855 - val_accuracy: 0.9625 - val_loss: 0.6682 - learning_rate: 2.0000e-04\n",
            "Epoch 16/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9625 - loss: 0.6509 - val_accuracy: 0.9613 - val_loss: 0.6428 - learning_rate: 2.0000e-04\n",
            "Epoch 17/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.9557 - loss: 0.6332 - val_accuracy: 0.9594 - val_loss: 0.6273 - learning_rate: 2.0000e-04\n",
            "Epoch 18/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.9613 - loss: 0.6047 - val_accuracy: 0.9619 - val_loss: 0.5988 - learning_rate: 2.0000e-04\n",
            "Epoch 19/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.9600 - loss: 0.5948 - val_accuracy: 0.9613 - val_loss: 0.5719 - learning_rate: 2.0000e-04\n",
            "Epoch 20/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - accuracy: 0.9657 - loss: 0.5679 - val_accuracy: 0.9650 - val_loss: 0.5556 - learning_rate: 2.0000e-04\n",
            "Epoch 21/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9639 - loss: 0.5419 - val_accuracy: 0.9656 - val_loss: 0.5353 - learning_rate: 2.0000e-04\n",
            "Epoch 22/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9724 - loss: 0.5115 - val_accuracy: 0.9675 - val_loss: 0.5202 - learning_rate: 2.0000e-04\n",
            "Epoch 23/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9711 - loss: 0.4958 - val_accuracy: 0.9638 - val_loss: 0.5097 - learning_rate: 2.0000e-04\n",
            "Epoch 24/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9670 - loss: 0.4888 - val_accuracy: 0.9663 - val_loss: 0.4919 - learning_rate: 2.0000e-04\n",
            "Epoch 25/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - accuracy: 0.9662 - loss: 0.4683 - val_accuracy: 0.9675 - val_loss: 0.4721 - learning_rate: 2.0000e-04\n",
            "Epoch 26/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9680 - loss: 0.4553 - val_accuracy: 0.9650 - val_loss: 0.4608 - learning_rate: 2.0000e-04\n",
            "Epoch 27/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.9728 - loss: 0.4273 - val_accuracy: 0.9675 - val_loss: 0.4360 - learning_rate: 2.0000e-04\n",
            "Epoch 28/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.9634 - loss: 0.4288 - val_accuracy: 0.9613 - val_loss: 0.4456 - learning_rate: 2.0000e-04\n",
            "Epoch 29/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - accuracy: 0.9760 - loss: 0.3989 - val_accuracy: 0.9619 - val_loss: 0.4266 - learning_rate: 2.0000e-04\n",
            "Epoch 30/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9678 - loss: 0.3959 - val_accuracy: 0.9675 - val_loss: 0.4114 - learning_rate: 2.0000e-04\n",
            "Epoch 31/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9757 - loss: 0.3687 - val_accuracy: 0.9675 - val_loss: 0.3939 - learning_rate: 2.0000e-04\n",
            "Epoch 32/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.9727 - loss: 0.3698 - val_accuracy: 0.9669 - val_loss: 0.3859 - learning_rate: 2.0000e-04\n",
            "Epoch 33/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9745 - loss: 0.3518 - val_accuracy: 0.9625 - val_loss: 0.3888 - learning_rate: 2.0000e-04\n",
            "Epoch 34/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.9748 - loss: 0.3456 - val_accuracy: 0.9663 - val_loss: 0.3682 - learning_rate: 2.0000e-04\n",
            "Epoch 35/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - accuracy: 0.9759 - loss: 0.3303 - val_accuracy: 0.9669 - val_loss: 0.3540 - learning_rate: 2.0000e-04\n",
            "Epoch 36/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9749 - loss: 0.3250 - val_accuracy: 0.9694 - val_loss: 0.3562 - learning_rate: 2.0000e-04\n",
            "Epoch 37/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9764 - loss: 0.3086 - val_accuracy: 0.9688 - val_loss: 0.3380 - learning_rate: 2.0000e-04\n",
            "Epoch 38/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 0.9815 - loss: 0.2939 - val_accuracy: 0.9613 - val_loss: 0.3445 - learning_rate: 2.0000e-04\n",
            "Epoch 39/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.9769 - loss: 0.2970 - val_accuracy: 0.9663 - val_loss: 0.3300 - learning_rate: 2.0000e-04\n",
            "Epoch 40/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.9789 - loss: 0.2823 - val_accuracy: 0.9712 - val_loss: 0.3120 - learning_rate: 2.0000e-04\n",
            "Epoch 41/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.9814 - loss: 0.2660 - val_accuracy: 0.9700 - val_loss: 0.3109 - learning_rate: 2.0000e-04\n",
            "Epoch 42/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 0.9794 - loss: 0.2623 - val_accuracy: 0.9681 - val_loss: 0.3034 - learning_rate: 2.0000e-04\n",
            "Epoch 43/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.9822 - loss: 0.2502 - val_accuracy: 0.9700 - val_loss: 0.2947 - learning_rate: 2.0000e-04\n",
            "Epoch 44/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9828 - loss: 0.2392 - val_accuracy: 0.9688 - val_loss: 0.2838 - learning_rate: 2.0000e-04\n",
            "Epoch 45/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9774 - loss: 0.2427 - val_accuracy: 0.9694 - val_loss: 0.2746 - learning_rate: 2.0000e-04\n",
            "Epoch 46/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - accuracy: 0.9808 - loss: 0.2321 - val_accuracy: 0.9681 - val_loss: 0.2831 - learning_rate: 2.0000e-04\n",
            "Epoch 47/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9801 - loss: 0.2278 - val_accuracy: 0.9681 - val_loss: 0.2862 - learning_rate: 2.0000e-04\n",
            "Epoch 48/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9772 - loss: 0.2218 - val_accuracy: 0.9675 - val_loss: 0.2679 - learning_rate: 2.0000e-04\n",
            "Epoch 49/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9854 - loss: 0.2025 - val_accuracy: 0.9688 - val_loss: 0.2532 - learning_rate: 2.0000e-04\n",
            "Epoch 50/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.9847 - loss: 0.2012 - val_accuracy: 0.9675 - val_loss: 0.2571 - learning_rate: 2.0000e-04\n",
            "Epoch 1/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - accuracy: 0.5528 - loss: 2.4233 - val_accuracy: 0.8863 - val_loss: 1.4867 - learning_rate: 2.0000e-04\n",
            "Epoch 2/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - accuracy: 0.9039 - loss: 1.4067 - val_accuracy: 0.9356 - val_loss: 1.2510 - learning_rate: 2.0000e-04\n",
            "Epoch 3/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.9289 - loss: 1.2456 - val_accuracy: 0.9356 - val_loss: 1.1724 - learning_rate: 2.0000e-04\n",
            "Epoch 4/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9345 - loss: 1.1381 - val_accuracy: 0.9488 - val_loss: 1.0580 - learning_rate: 2.0000e-04\n",
            "Epoch 5/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.9376 - loss: 1.0725 - val_accuracy: 0.9506 - val_loss: 1.0128 - learning_rate: 2.0000e-04\n",
            "Epoch 6/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 0.9450 - loss: 0.9860 - val_accuracy: 0.9494 - val_loss: 0.9703 - learning_rate: 2.0000e-04\n",
            "Epoch 7/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9404 - loss: 0.9506 - val_accuracy: 0.9500 - val_loss: 0.9011 - learning_rate: 2.0000e-04\n",
            "Epoch 8/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9510 - loss: 0.9025 - val_accuracy: 0.9531 - val_loss: 0.8810 - learning_rate: 2.0000e-04\n",
            "Epoch 9/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.9536 - loss: 0.8544 - val_accuracy: 0.9550 - val_loss: 0.8466 - learning_rate: 2.0000e-04\n",
            "Epoch 10/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9557 - loss: 0.8184 - val_accuracy: 0.9600 - val_loss: 0.7923 - learning_rate: 2.0000e-04\n",
            "Epoch 11/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - accuracy: 0.9573 - loss: 0.7790 - val_accuracy: 0.9613 - val_loss: 0.7634 - learning_rate: 2.0000e-04\n",
            "Epoch 12/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9590 - loss: 0.7497 - val_accuracy: 0.9600 - val_loss: 0.7336 - learning_rate: 2.0000e-04\n",
            "Epoch 13/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9593 - loss: 0.7262 - val_accuracy: 0.9600 - val_loss: 0.7088 - learning_rate: 2.0000e-04\n",
            "Epoch 14/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.9594 - loss: 0.7007 - val_accuracy: 0.9600 - val_loss: 0.6791 - learning_rate: 2.0000e-04\n",
            "Epoch 15/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - accuracy: 0.9660 - loss: 0.6598 - val_accuracy: 0.9588 - val_loss: 0.6578 - learning_rate: 2.0000e-04\n",
            "Epoch 16/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - accuracy: 0.9593 - loss: 0.6392 - val_accuracy: 0.9613 - val_loss: 0.6384 - learning_rate: 2.0000e-04\n",
            "Epoch 17/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9618 - loss: 0.6178 - val_accuracy: 0.9594 - val_loss: 0.6102 - learning_rate: 2.0000e-04\n",
            "Epoch 18/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9617 - loss: 0.5910 - val_accuracy: 0.9631 - val_loss: 0.5802 - learning_rate: 2.0000e-04\n",
            "Epoch 19/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9625 - loss: 0.5819 - val_accuracy: 0.9650 - val_loss: 0.5630 - learning_rate: 2.0000e-04\n",
            "Epoch 20/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9617 - loss: 0.5524 - val_accuracy: 0.9606 - val_loss: 0.5478 - learning_rate: 2.0000e-04\n",
            "Epoch 21/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - accuracy: 0.9689 - loss: 0.5290 - val_accuracy: 0.9600 - val_loss: 0.5300 - learning_rate: 2.0000e-04\n",
            "Epoch 22/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.9703 - loss: 0.5043 - val_accuracy: 0.9613 - val_loss: 0.5128 - learning_rate: 2.0000e-04\n",
            "Epoch 23/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9711 - loss: 0.4882 - val_accuracy: 0.9606 - val_loss: 0.4967 - learning_rate: 2.0000e-04\n",
            "Epoch 24/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9741 - loss: 0.4661 - val_accuracy: 0.9644 - val_loss: 0.4854 - learning_rate: 2.0000e-04\n",
            "Epoch 25/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.9632 - loss: 0.4741 - val_accuracy: 0.9613 - val_loss: 0.4781 - learning_rate: 2.0000e-04\n",
            "Epoch 26/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9688 - loss: 0.4501 - val_accuracy: 0.9688 - val_loss: 0.4391 - learning_rate: 2.0000e-04\n",
            "Epoch 27/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9712 - loss: 0.4238 - val_accuracy: 0.9669 - val_loss: 0.4429 - learning_rate: 2.0000e-04\n",
            "Epoch 28/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.9718 - loss: 0.4137 - val_accuracy: 0.9619 - val_loss: 0.4368 - learning_rate: 2.0000e-04\n",
            "Epoch 29/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - accuracy: 0.9718 - loss: 0.4019 - val_accuracy: 0.9694 - val_loss: 0.4029 - learning_rate: 2.0000e-04\n",
            "Epoch 30/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - accuracy: 0.9691 - loss: 0.3942 - val_accuracy: 0.9694 - val_loss: 0.3900 - learning_rate: 2.0000e-04\n",
            "Epoch 31/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9729 - loss: 0.3774 - val_accuracy: 0.9675 - val_loss: 0.3893 - learning_rate: 2.0000e-04\n",
            "Epoch 32/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.9712 - loss: 0.3619 - val_accuracy: 0.9694 - val_loss: 0.3687 - learning_rate: 2.0000e-04\n",
            "Epoch 33/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.9769 - loss: 0.3473 - val_accuracy: 0.9663 - val_loss: 0.3590 - learning_rate: 2.0000e-04\n",
            "Epoch 34/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - accuracy: 0.9717 - loss: 0.3370 - val_accuracy: 0.9675 - val_loss: 0.3458 - learning_rate: 2.0000e-04\n",
            "Epoch 35/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.9754 - loss: 0.3256 - val_accuracy: 0.9737 - val_loss: 0.3362 - learning_rate: 2.0000e-04\n",
            "Epoch 36/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9783 - loss: 0.3165 - val_accuracy: 0.9737 - val_loss: 0.3209 - learning_rate: 2.0000e-04\n",
            "Epoch 37/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.9753 - loss: 0.3085 - val_accuracy: 0.9712 - val_loss: 0.3141 - learning_rate: 2.0000e-04\n",
            "Epoch 38/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.9805 - loss: 0.2861 - val_accuracy: 0.9663 - val_loss: 0.3165 - learning_rate: 2.0000e-04\n",
            "Epoch 39/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - accuracy: 0.9715 - loss: 0.3036 - val_accuracy: 0.9700 - val_loss: 0.3127 - learning_rate: 2.0000e-04\n",
            "Epoch 40/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9782 - loss: 0.2715 - val_accuracy: 0.9688 - val_loss: 0.3044 - learning_rate: 2.0000e-04\n",
            "Epoch 41/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9746 - loss: 0.2759 - val_accuracy: 0.9656 - val_loss: 0.3069 - learning_rate: 2.0000e-04\n",
            "Epoch 42/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 0.9821 - loss: 0.2531 - val_accuracy: 0.9694 - val_loss: 0.2909 - learning_rate: 2.0000e-04\n",
            "Epoch 43/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.9794 - loss: 0.2527 - val_accuracy: 0.9744 - val_loss: 0.2758 - learning_rate: 2.0000e-04\n",
            "Epoch 44/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9810 - loss: 0.2422 - val_accuracy: 0.9719 - val_loss: 0.2731 - learning_rate: 2.0000e-04\n",
            "Epoch 45/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.9815 - loss: 0.2329 - val_accuracy: 0.9712 - val_loss: 0.2695 - learning_rate: 2.0000e-04\n",
            "Epoch 46/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.9799 - loss: 0.2355 - val_accuracy: 0.9744 - val_loss: 0.2544 - learning_rate: 2.0000e-04\n",
            "Epoch 47/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.9812 - loss: 0.2215 - val_accuracy: 0.9731 - val_loss: 0.2468 - learning_rate: 2.0000e-04\n",
            "Epoch 48/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9781 - loss: 0.2214 - val_accuracy: 0.9706 - val_loss: 0.2472 - learning_rate: 2.0000e-04\n",
            "Epoch 49/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9797 - loss: 0.2151 - val_accuracy: 0.9762 - val_loss: 0.2422 - learning_rate: 2.0000e-04\n",
            "Epoch 50/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 0.9792 - loss: 0.2076 - val_accuracy: 0.9706 - val_loss: 0.2427 - learning_rate: 2.0000e-04\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.impute import KNNImputer\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from scipy.signal import savgol_filter\n",
        "\n",
        "def load_data():\n",
        "    train = pd.read_csv(\"hacktrain.csv\")\n",
        "    test = pd.read_csv(\"hacktest.csv\")\n",
        "    return train, test\n",
        "train, test = load_data()\n",
        "train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "id": "F3khA9LuH0ZP",
        "outputId": "2be1be15-1505-4274-ee8c-f842cdac1b98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Unnamed: 0     ID       class  20150720_N  20150602_N  20150517_N  \\\n",
              "0              0      1       water    637.5950     658.668   -1882.030   \n",
              "1              1      2       water    634.2400     593.705   -1625.790   \n",
              "2              3      4       water     58.0174   -1599.160         NaN   \n",
              "3              4      5       water     72.5180         NaN     380.436   \n",
              "4              7      8       water   1136.4400         NaN         NaN   \n",
              "...          ...    ...         ...         ...         ...         ...   \n",
              "7995       10537  10538  impervious   1207.7000     984.620         NaN   \n",
              "7996       10538  10539  impervious   2170.3500    1419.720    1361.000   \n",
              "7997       10541  10542  impervious   1895.6800    1454.740         NaN   \n",
              "7998       10542  10543  impervious   3465.7400    1283.320     413.412   \n",
              "7999       10544  10545  impervious   6941.1900    1667.870    5084.780   \n",
              "\n",
              "      20150501_N  20150415_N  20150330_N  20150314_N  ...  20140610_N  \\\n",
              "0       -1924.36     997.904   -1739.990     630.087  ...         NaN   \n",
              "1       -1672.32     914.198    -692.386     707.626  ...         NaN   \n",
              "2       -1052.63         NaN   -1564.630         NaN  ...   -1025.880   \n",
              "3       -1256.93     515.805   -1413.180    -802.942  ...   -1813.950   \n",
              "4        1647.83    1935.800         NaN    2158.980  ...    1535.000   \n",
              "...          ...         ...         ...         ...  ...         ...   \n",
              "7995     1166.25     937.478    1072.700     823.896  ...    1117.740   \n",
              "7996     1478.71     983.911    1262.110    1422.860  ...     984.634   \n",
              "7997     1033.56    1930.380    1057.150    1471.600  ...     888.408   \n",
              "7998     4391.05    1146.820    4473.050    1614.750  ...    5833.760   \n",
              "7999         NaN    1588.950    5978.190         NaN  ...    7352.570   \n",
              "\n",
              "      20140525_N  20140509_N  20140423_N  20140407_N  20140322_N  20140218_N  \\\n",
              "0      -1043.160   -1942.490     267.138         NaN         NaN     211.328   \n",
              "1       -933.934    -625.385     120.059     364.858     476.972     220.878   \n",
              "2        368.622         NaN   -1227.800     304.621         NaN     369.214   \n",
              "3        155.624         NaN    -924.073     432.150     282.833     298.320   \n",
              "4       1959.430    -279.317    -384.915    -113.406    1020.720    1660.650   \n",
              "...          ...         ...         ...         ...         ...         ...   \n",
              "7995    1176.600    1044.110         NaN     369.082     465.843     362.882   \n",
              "7996    2128.970    1379.660         NaN     762.633     485.204     446.724   \n",
              "7997    2093.020    1232.110    1190.830    1441.460    1170.880    1095.000   \n",
              "7998    4047.320    4515.800     433.177     277.296     744.143         NaN   \n",
              "7999    3289.860    3729.150    1994.980         NaN    5299.900         NaN   \n",
              "\n",
              "      20140202_N  20140117_N  20140101_N  \n",
              "0      -2203.020    -1180.19     433.906  \n",
              "1      -2250.000    -1360.56     524.075  \n",
              "2      -2202.120         NaN   -1343.550  \n",
              "3      -2197.360         NaN    -826.727  \n",
              "4       -116.801     -568.05   -1357.140  \n",
              "...          ...         ...         ...  \n",
              "7995     979.795         NaN     433.659  \n",
              "7996     771.747     1589.06     506.936  \n",
              "7997    1818.650     2501.72    1247.770  \n",
              "7998    3759.710         NaN     388.346  \n",
              "7999    5983.130     1249.71    2424.230  \n",
              "\n",
              "[8000 rows x 30 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e392fb33-2688-4468-9b25-dcbdd2a9f122\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>ID</th>\n",
              "      <th>class</th>\n",
              "      <th>20150720_N</th>\n",
              "      <th>20150602_N</th>\n",
              "      <th>20150517_N</th>\n",
              "      <th>20150501_N</th>\n",
              "      <th>20150415_N</th>\n",
              "      <th>20150330_N</th>\n",
              "      <th>20150314_N</th>\n",
              "      <th>...</th>\n",
              "      <th>20140610_N</th>\n",
              "      <th>20140525_N</th>\n",
              "      <th>20140509_N</th>\n",
              "      <th>20140423_N</th>\n",
              "      <th>20140407_N</th>\n",
              "      <th>20140322_N</th>\n",
              "      <th>20140218_N</th>\n",
              "      <th>20140202_N</th>\n",
              "      <th>20140117_N</th>\n",
              "      <th>20140101_N</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>water</td>\n",
              "      <td>637.5950</td>\n",
              "      <td>658.668</td>\n",
              "      <td>-1882.030</td>\n",
              "      <td>-1924.36</td>\n",
              "      <td>997.904</td>\n",
              "      <td>-1739.990</td>\n",
              "      <td>630.087</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-1043.160</td>\n",
              "      <td>-1942.490</td>\n",
              "      <td>267.138</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>211.328</td>\n",
              "      <td>-2203.020</td>\n",
              "      <td>-1180.19</td>\n",
              "      <td>433.906</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>water</td>\n",
              "      <td>634.2400</td>\n",
              "      <td>593.705</td>\n",
              "      <td>-1625.790</td>\n",
              "      <td>-1672.32</td>\n",
              "      <td>914.198</td>\n",
              "      <td>-692.386</td>\n",
              "      <td>707.626</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-933.934</td>\n",
              "      <td>-625.385</td>\n",
              "      <td>120.059</td>\n",
              "      <td>364.858</td>\n",
              "      <td>476.972</td>\n",
              "      <td>220.878</td>\n",
              "      <td>-2250.000</td>\n",
              "      <td>-1360.56</td>\n",
              "      <td>524.075</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>water</td>\n",
              "      <td>58.0174</td>\n",
              "      <td>-1599.160</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-1052.63</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-1564.630</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>-1025.880</td>\n",
              "      <td>368.622</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-1227.800</td>\n",
              "      <td>304.621</td>\n",
              "      <td>NaN</td>\n",
              "      <td>369.214</td>\n",
              "      <td>-2202.120</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-1343.550</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>water</td>\n",
              "      <td>72.5180</td>\n",
              "      <td>NaN</td>\n",
              "      <td>380.436</td>\n",
              "      <td>-1256.93</td>\n",
              "      <td>515.805</td>\n",
              "      <td>-1413.180</td>\n",
              "      <td>-802.942</td>\n",
              "      <td>...</td>\n",
              "      <td>-1813.950</td>\n",
              "      <td>155.624</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-924.073</td>\n",
              "      <td>432.150</td>\n",
              "      <td>282.833</td>\n",
              "      <td>298.320</td>\n",
              "      <td>-2197.360</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-826.727</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>water</td>\n",
              "      <td>1136.4400</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1647.83</td>\n",
              "      <td>1935.800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2158.980</td>\n",
              "      <td>...</td>\n",
              "      <td>1535.000</td>\n",
              "      <td>1959.430</td>\n",
              "      <td>-279.317</td>\n",
              "      <td>-384.915</td>\n",
              "      <td>-113.406</td>\n",
              "      <td>1020.720</td>\n",
              "      <td>1660.650</td>\n",
              "      <td>-116.801</td>\n",
              "      <td>-568.05</td>\n",
              "      <td>-1357.140</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7995</th>\n",
              "      <td>10537</td>\n",
              "      <td>10538</td>\n",
              "      <td>impervious</td>\n",
              "      <td>1207.7000</td>\n",
              "      <td>984.620</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1166.25</td>\n",
              "      <td>937.478</td>\n",
              "      <td>1072.700</td>\n",
              "      <td>823.896</td>\n",
              "      <td>...</td>\n",
              "      <td>1117.740</td>\n",
              "      <td>1176.600</td>\n",
              "      <td>1044.110</td>\n",
              "      <td>NaN</td>\n",
              "      <td>369.082</td>\n",
              "      <td>465.843</td>\n",
              "      <td>362.882</td>\n",
              "      <td>979.795</td>\n",
              "      <td>NaN</td>\n",
              "      <td>433.659</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7996</th>\n",
              "      <td>10538</td>\n",
              "      <td>10539</td>\n",
              "      <td>impervious</td>\n",
              "      <td>2170.3500</td>\n",
              "      <td>1419.720</td>\n",
              "      <td>1361.000</td>\n",
              "      <td>1478.71</td>\n",
              "      <td>983.911</td>\n",
              "      <td>1262.110</td>\n",
              "      <td>1422.860</td>\n",
              "      <td>...</td>\n",
              "      <td>984.634</td>\n",
              "      <td>2128.970</td>\n",
              "      <td>1379.660</td>\n",
              "      <td>NaN</td>\n",
              "      <td>762.633</td>\n",
              "      <td>485.204</td>\n",
              "      <td>446.724</td>\n",
              "      <td>771.747</td>\n",
              "      <td>1589.06</td>\n",
              "      <td>506.936</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7997</th>\n",
              "      <td>10541</td>\n",
              "      <td>10542</td>\n",
              "      <td>impervious</td>\n",
              "      <td>1895.6800</td>\n",
              "      <td>1454.740</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1033.56</td>\n",
              "      <td>1930.380</td>\n",
              "      <td>1057.150</td>\n",
              "      <td>1471.600</td>\n",
              "      <td>...</td>\n",
              "      <td>888.408</td>\n",
              "      <td>2093.020</td>\n",
              "      <td>1232.110</td>\n",
              "      <td>1190.830</td>\n",
              "      <td>1441.460</td>\n",
              "      <td>1170.880</td>\n",
              "      <td>1095.000</td>\n",
              "      <td>1818.650</td>\n",
              "      <td>2501.72</td>\n",
              "      <td>1247.770</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7998</th>\n",
              "      <td>10542</td>\n",
              "      <td>10543</td>\n",
              "      <td>impervious</td>\n",
              "      <td>3465.7400</td>\n",
              "      <td>1283.320</td>\n",
              "      <td>413.412</td>\n",
              "      <td>4391.05</td>\n",
              "      <td>1146.820</td>\n",
              "      <td>4473.050</td>\n",
              "      <td>1614.750</td>\n",
              "      <td>...</td>\n",
              "      <td>5833.760</td>\n",
              "      <td>4047.320</td>\n",
              "      <td>4515.800</td>\n",
              "      <td>433.177</td>\n",
              "      <td>277.296</td>\n",
              "      <td>744.143</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3759.710</td>\n",
              "      <td>NaN</td>\n",
              "      <td>388.346</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7999</th>\n",
              "      <td>10544</td>\n",
              "      <td>10545</td>\n",
              "      <td>impervious</td>\n",
              "      <td>6941.1900</td>\n",
              "      <td>1667.870</td>\n",
              "      <td>5084.780</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1588.950</td>\n",
              "      <td>5978.190</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>7352.570</td>\n",
              "      <td>3289.860</td>\n",
              "      <td>3729.150</td>\n",
              "      <td>1994.980</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5299.900</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5983.130</td>\n",
              "      <td>1249.71</td>\n",
              "      <td>2424.230</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8000 rows × 30 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e392fb33-2688-4468-9b25-dcbdd2a9f122')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e392fb33-2688-4468-9b25-dcbdd2a9f122 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e392fb33-2688-4468-9b25-dcbdd2a9f122');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-072baf5f-5042-4c29-8342-01ac71572a67\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-072baf5f-5042-4c29-8342-01ac71572a67')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-072baf5f-5042-4c29-8342-01ac71572a67 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_2ff2c26b-8119-49a5-97d7-e456b8391a48\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('train')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_2ff2c26b-8119-49a5-97d7-e456b8391a48 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('train');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def preprocess(df):\n",
        "    df = df.copy()\n",
        "    ndvi_cols = [col for col in df.columns if '_N' in col]\n",
        "\n",
        "    # Temporal interpolation for NDVI\n",
        "    df[ndvi_cols] = df[ndvi_cols].interpolate(axis=1, limit_direction='both')\n",
        "\n",
        "    # Apply Savitzky-Golay filter for smoothing\n",
        "    df[ndvi_cols] = savgol_filter(df[ndvi_cols], window_length=5, polyorder=2, axis=1)\n",
        "\n",
        "    # Extract temporal features\n",
        "    df['ndvi_mean'] = df[ndvi_cols].mean(axis=1)\n",
        "    df['ndvi_std'] = df[ndvi_cols].std(axis=1)\n",
        "    df['ndvi_amp'] = df[ndvi_cols].max(axis=1) - df[ndvi_cols].min(axis=1)\n",
        "\n",
        "    # Seasonal features (assuming columns are in chronological order)\n",
        "    spring = ndvi_cols[:7]  # First 7 time points as spring\n",
        "    summer = ndvi_cols[7:14]\n",
        "    fall = ndvi_cols[14:21]\n",
        "    winter = ndvi_cols[21:]\n",
        "\n",
        "    df['spring_mean'] = df[spring].mean(axis=1)\n",
        "    df['summer_mean'] = df[summer].mean(axis=1)\n",
        "    df['fall_mean'] = df[fall].mean(axis=1)\n",
        "    df['winter_mean'] = df[winter].mean(axis=1)\n",
        "\n",
        "    return df\n",
        "\n",
        "def main():\n",
        "    train, test = load_data()\n",
        "\n",
        "    # Preprocess\n",
        "    train_processed = preprocess(train)\n",
        "    test_processed = preprocess(test)\n",
        "\n",
        "    # Prepare data\n",
        "    X_train = train_processed.drop(columns=['ID', 'class'])\n",
        "    y_train = train_processed['class']\n",
        "    X_test = test_processed.drop(columns=['ID'])\n",
        "\n",
        "    # Encode labels\n",
        "    le = LabelEncoder()\n",
        "    y_train = le.fit_transform(y_train)\n",
        "\n",
        "    # Build pipeline\n",
        "    pipeline = make_pipeline(\n",
        "        KNNImputer(n_neighbors=5),\n",
        "        StandardScaler(),\n",
        "        SelectKBest(f_classif, k=20),\n",
        "        LogisticRegression(multi_class='multinomial',\n",
        "                          solver='lbfgs',\n",
        "                          max_iter=1000,\n",
        "                          C=0.1,\n",
        "                          penalty='l2')\n",
        "    )\n",
        "\n",
        "    # Train and predict\n",
        "    pipeline.fit(X_train, y_train)\n",
        "    test_pred = pipeline.predict(X_test)\n",
        "    test_pred_labels = le.inverse_transform(test_pred)\n",
        "\n",
        "    # Save results\n",
        "    submission = pd.DataFrame({'ID': test['ID'], 'class': test_pred_labels})\n",
        "    submission.to_csv(\"lr_submission.csv\", index=False)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5SS5NryFCGF",
        "outputId": "fe8944fd-5dba-4a8c-d87f-e0007903803c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WJvpoM0aH7WR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.impute import KNNImputer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import classification_report\n",
        "from scipy.signal import savgol_filter\n",
        "\n",
        "df = pd.read_csv(\"hacktrain.csv\")\n",
        "ID = df['ID']\n",
        "df.drop(columns=['ID'], inplace=True)\n",
        "\n",
        "numeric_cols = df.select_dtypes(include=np.number).columns\n",
        "df[numeric_cols] = savgol_filter(df[numeric_cols], window_length=5, polyorder=2, axis=1)\n",
        "imputer = KNNImputer(n_neighbors=3)\n",
        "df[numeric_cols] = imputer.fit_transform(df[numeric_cols])\n",
        "\n",
        "df['mean_ndvi'] = df[numeric_cols].mean(axis=1)\n",
        "df['std_ndvi'] = df[numeric_cols].std(axis=1)\n",
        "df['trend'] = df[numeric_cols].apply(lambda x: np.polyfit(range(len(x)), x, 1)[0], axis=1)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(df.drop(columns=['class']))\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(df['class'])\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "val_reports = []\n",
        "\n",
        "for train_idx, val_idx in skf.split(X, y):\n",
        "    X_train, X_val = X[train_idx], X[val_idx]\n",
        "    y_train, y_val = y[train_idx], y[val_idx]\n",
        "\n",
        "    model = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000, C=0.5, penalty='l2')\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    y_val_pred = model.predict(X_val)\n",
        "    report = classification_report(y_val, y_val_pred, labels=list(range(len(label_encoder.classes_))),\n",
        "                                  target_names=label_encoder.classes_, output_dict=False)\n",
        "    val_reports.append(report)\n",
        "    print(f\"Fold Validation Classification Report:\\n{report}\")\n",
        "\n",
        "test_data = pd.read_csv(\"hacktest.csv\")\n",
        "test_ID = test_data['ID']\n",
        "test_data.drop(['ID'], axis=1, inplace=True)\n",
        "\n",
        "test_data[numeric_cols] = imputer.transform(test_data[numeric_cols])\n",
        "test_data['mean_ndvi'] = test_data[numeric_cols].mean(axis=1)\n",
        "test_data['std_ndvi'] = test_data[numeric_cols].std(axis=1)\n",
        "test_data['trend'] = test_data[numeric_cols].apply(lambda x: np.polyfit(range(len(x)), x, 1)[0], axis=1)\n",
        "\n",
        "X_test_final = scaler.transform(test_data)\n",
        "y_test_pred = model.predict(X_test_final)\n",
        "y_decoded = label_encoder.inverse_transform(y_test_pred)\n",
        "\n",
        "result = pd.DataFrame({'ID': test_ID, 'class': y_decoded})\n",
        "result.to_csv(\"submission_lr.csv\", index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4GPt75_IF94",
        "outputId": "8b6bb804-1631-4c5a-91ab-7f090ed7db7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold Validation Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        farm       0.63      0.46      0.53       168\n",
            "      forest       0.90      0.97      0.93      1232\n",
            "       grass       0.54      0.36      0.43        39\n",
            "  impervious       0.80      0.62      0.70       134\n",
            "     orchard       1.00      0.17      0.29         6\n",
            "       water       1.00      0.67      0.80        21\n",
            "\n",
            "    accuracy                           0.87      1600\n",
            "   macro avg       0.81      0.54      0.61      1600\n",
            "weighted avg       0.86      0.87      0.86      1600\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold Validation Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        farm       0.66      0.46      0.54       168\n",
            "      forest       0.91      0.97      0.94      1232\n",
            "       grass       0.48      0.26      0.33        39\n",
            "  impervious       0.71      0.70      0.71       134\n",
            "     orchard       0.00      0.00      0.00         6\n",
            "       water       0.91      0.48      0.62        21\n",
            "\n",
            "    accuracy                           0.87      1600\n",
            "   macro avg       0.61      0.48      0.52      1600\n",
            "weighted avg       0.85      0.87      0.85      1600\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold Validation Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        farm       0.58      0.45      0.51       168\n",
            "      forest       0.90      0.97      0.93      1232\n",
            "       grass       0.67      0.41      0.51        39\n",
            "  impervious       0.79      0.56      0.66       134\n",
            "     orchard       0.00      0.00      0.00         6\n",
            "       water       0.86      0.57      0.69        21\n",
            "\n",
            "    accuracy                           0.86      1600\n",
            "   macro avg       0.63      0.49      0.55      1600\n",
            "weighted avg       0.84      0.86      0.85      1600\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold Validation Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        farm       0.66      0.46      0.54       169\n",
            "      forest       0.89      0.97      0.93      1232\n",
            "       grass       0.47      0.21      0.29        39\n",
            "  impervious       0.69      0.63      0.66       133\n",
            "     orchard       0.00      0.00      0.00         6\n",
            "       water       1.00      0.29      0.44        21\n",
            "\n",
            "    accuracy                           0.86      1600\n",
            "   macro avg       0.62      0.43      0.48      1600\n",
            "weighted avg       0.84      0.86      0.84      1600\n",
            "\n",
            "Fold Validation Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        farm       0.67      0.45      0.54       168\n",
            "      forest       0.89      0.97      0.93      1231\n",
            "       grass       0.57      0.30      0.39        40\n",
            "  impervious       0.74      0.65      0.69       134\n",
            "     orchard       1.00      0.17      0.29         6\n",
            "       water       0.67      0.29      0.40        21\n",
            "\n",
            "    accuracy                           0.86      1600\n",
            "   macro avg       0.76      0.47      0.54      1600\n",
            "weighted avg       0.85      0.86      0.85      1600\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "Ma_CTqHNIlEN",
        "outputId": "76fc3c26-bf95-4f90-95af-bc2bdaf43f2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        ID   class\n",
              "0        1   water\n",
              "1        2  forest\n",
              "2        3  forest\n",
              "3        4    farm\n",
              "4        5  forest\n",
              "...    ...     ...\n",
              "2840  2841   water\n",
              "2841  2842   water\n",
              "2842  2843   water\n",
              "2843  2844   water\n",
              "2844  2845   water\n",
              "\n",
              "[2845 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4b46d2c1-6288-4b89-be69-818b38c9e19f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>water</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>forest</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>forest</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>farm</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>forest</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2840</th>\n",
              "      <td>2841</td>\n",
              "      <td>water</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2841</th>\n",
              "      <td>2842</td>\n",
              "      <td>water</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2842</th>\n",
              "      <td>2843</td>\n",
              "      <td>water</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2843</th>\n",
              "      <td>2844</td>\n",
              "      <td>water</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2844</th>\n",
              "      <td>2845</td>\n",
              "      <td>water</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2845 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4b46d2c1-6288-4b89-be69-818b38c9e19f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4b46d2c1-6288-4b89-be69-818b38c9e19f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4b46d2c1-6288-4b89-be69-818b38c9e19f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-6f3d3a45-b2f0-41c1-bc52-e5f66683c215\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6f3d3a45-b2f0-41c1-bc52-e5f66683c215')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-6f3d3a45-b2f0-41c1-bc52-e5f66683c215 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_44be7e8c-f786-4a5e-849c-c235ca335610\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('result')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_44be7e8c-f786-4a5e-849c-c235ca335610 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('result');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "result",
              "summary": "{\n  \"name\": \"result\",\n  \"rows\": 2845,\n  \"fields\": [\n    {\n      \"column\": \"ID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 821,\n        \"min\": 1,\n        \"max\": 2845,\n        \"num_unique_values\": 2845,\n        \"samples\": [\n          416,\n          2234,\n          1150\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"class\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"forest\",\n          \"grass\",\n          \"farm\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZaonFT16JCBR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}